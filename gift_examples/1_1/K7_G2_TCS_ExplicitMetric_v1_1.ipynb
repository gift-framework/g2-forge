{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/1.1/K7_G2_TCS_ExplicitMetric_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K₇ G₂ TCS Explicit Metric v1.1\n",
        "\n",
        "Complete TCS construction pipeline with:\n",
        "- Full TCS geometry (M₁, Neck, M₂) with **extended neck** (σ_neck = 5.0)\n",
        "- Neural φ-network with **torsion targeting** (not minimization)\n",
        "- Live Laplacian computation and harmonic extraction\n",
        "- Multi-phase curriculum learning with **per-phase early stopping**\n",
        "- **RG flow constraint** with geodesic integration\n",
        "- **AlphaInverseFunctional** for observable-based training\n",
        "- Full Yukawa tensor (21×21×77)\n",
        "- Checkpoint system with automatic resumption\n",
        "\n",
        "**v1.1**: Critical fix for torsion magnitude (||T|| target: 0.0164) + RG flow integration + extended neck geometry + systematic early stopping per phase\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import csr_matrix, lil_matrix, diags\n",
        "from scipy.sparse.linalg import eigsh, spsolve\n",
        "from scipy.spatial.transform import Rotation\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CONFIG = {\n",
        "    'n_grid': 16,\n",
        "    'n_grid_harmonics': 8,  # Reduced grid for harmonic extraction\n",
        "    'n_fourier': 10,\n",
        "    'hidden_dim': 256,\n",
        "    'n_layers': 6,\n",
        "    'batch_size': 1024,\n",
        "    'learning_rate': 5e-4,\n",
        "    'n_epochs_per_phase': 1500,\n",
        "    'checkpoint_freq': 500,\n",
        "    'checkpoint_dir': 'checkpoints_v1_1',\n",
        "\n",
        "    'tcs': {\n",
        "        'r_neck_start': 0.35,\n",
        "        'r_neck_end': 0.65,\n",
        "        'r_acyl_cutoff': 10.0,\n",
        "        'twist_angle': np.pi / 3,\n",
        "        'neck_width': 5.0,  # NEW v1.1: Extended neck for RG flow accumulation\n",
        "    },\n",
        "\n",
        "    'target': {\n",
        "        'det_g': 2.0,\n",
        "        'torsion_norm': 0.0164,  # Target torsion magnitude from GIFT calibration\n",
        "        'b2': 21,\n",
        "        'b3': 77,\n",
        "    },\n",
        "    \n",
        "    # NEW v1.1: Phase-specific torsion targets (gradual ramp-up)\n",
        "    'torsion_targets': {\n",
        "        1: 0.001,   # Phase 1: Establish geometry\n",
        "        2: 0.005,   # Phase 2: ACyl matching\n",
        "        3: 0.010,   # Phase 3: Cohomology refinement\n",
        "        4: 0.015,   # Phase 4: Pre-calibration\n",
        "        5: 0.0164   # Phase 5: Final GIFT target\n",
        "    },\n",
        "\n",
        "    'yukawa_samples': 200000,\n",
        "    'torsion_threshold': 1e-6,\n",
        "    'torsion_floor': 1e-9,\n",
        "\n",
        "    'phases': {\n",
        "        1: {\n",
        "            'name': 'TCS_Neck',\n",
        "            'weights': {\n",
        "                'torsion': 1.0,      # NEW: replaces separate dphi/dpsi\n",
        "                'det': 0.5,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 2.0,\n",
        "                'acyl': 0.0,\n",
        "                'harmonicity': 0.0,\n",
        "                'rg_flow': 0.0       # NEW v1.1\n",
        "            },\n",
        "            'early_stop': {         # NEW v1.1: Per-phase early stopping\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'neck_match': 1e-5,\n",
        "                    'det': 1e-5,\n",
        "                    'positivity': 1e-7\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        2: {\n",
        "            'name': 'ACyl_Matching',\n",
        "            'weights': {\n",
        "                'torsion': 0.8,\n",
        "                'det': 0.8,\n",
        "                'positivity': 1.5,\n",
        "                'neck_match': 0.5,\n",
        "                'acyl': 0.5,\n",
        "                'harmonicity': 0.0,\n",
        "                'rg_flow': 0.0\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'acyl': 1e-5,\n",
        "                    'det': 1e-5,\n",
        "                    'torsion_target_reached': True  # Check if within 20% of target\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        3: {\n",
        "            'name': 'Cohomology_Refinement',\n",
        "            'weights': {\n",
        "                'torsion': 0.6,\n",
        "                'det': 0.5,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 0.5,\n",
        "                'acyl': 1.0,\n",
        "                'harmonicity': 1.0,\n",
        "                'rg_flow': 0.0\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'harmonicity': 1e-4,\n",
        "                    'torsion_target_reached': True\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        4: {\n",
        "            'name': 'Harmonic_Extraction',\n",
        "            'weights': {\n",
        "                'torsion': 0.5,\n",
        "                'det': 1.0,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 0.2,\n",
        "                'acyl': 0.5,\n",
        "                'harmonicity': 3.0,\n",
        "                'rg_flow': 0.1       # Start introducing RG flow\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'harmonicity': 5e-5,\n",
        "                    'torsion_target_reached': True\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        5: {\n",
        "            'name': 'RG_Calibration',\n",
        "            'weights': {\n",
        "                'torsion': 0.3,      # Reduced from 3.0 to allow RG flow to dominate\n",
        "                'det': 2.0,\n",
        "                'positivity': 2.0,\n",
        "                'neck_match': 0.1,\n",
        "                'acyl': 0.2,\n",
        "                'harmonicity': 2.0,\n",
        "                'rg_flow': 1.0       # Full RG flow enforcement\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 300,\n",
        "                'criteria': {\n",
        "                    'torsion_target_reached': True,\n",
        "                    'rg_flow': 0.01,  # Δα⁻¹ within tolerance\n",
        "                    'det': 1e-6,\n",
        "                    'positivity': 1e-8\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "    \n",
        "    # NEW v1.1: RG flow configuration\n",
        "    'rg_flow': {\n",
        "        'lambda_max': 39.44,           # ln(M_Planck/M_Z)\n",
        "        'target_delta_alpha': -0.9,    # QED running\n",
        "        'n_integration_steps': 100,\n",
        "        'geodesic_batch_freq': 0.1,    # Compute on 10% of batches for memory\n",
        "        'calibration_epoch': 6000,     # After Phase 4, before Phase 5\n",
        "    }\n",
        "}\n",
        "\n",
        "Path(CONFIG['checkpoint_dir']).mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Training grid: {CONFIG['n_grid']}^7\")\n",
        "print(f\"Harmonics grid: {CONFIG['n_grid_harmonics']}^7\")\n",
        "print(f\"Target: b₂={CONFIG['target']['b2']}, b₃={CONFIG['target']['b3']}\")\n",
        "print(f\"Target torsion: ||T||={CONFIG['target']['torsion_norm']}\")\n",
        "print(f\"Epochs per phase: {CONFIG['n_epochs_per_phase']}\")\n",
        "print(f\"Phases: {len(CONFIG['phases'])}\")\n",
        "print(f\"Extended neck width: σ_neck={CONFIG['tcs']['neck_width']}\")\n",
        "print(f\"RG flow: λ_max={CONFIG['rg_flow']['lambda_max']}, Δα⁻¹={CONFIG['rg_flow']['target_delta_alpha']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Complete TCS Geometry with Extended Neck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ACylPotentials:\n",
        "    def __init__(self, r_cutoff: float = 10.0):\n",
        "        self.r_cutoff = r_cutoff\n",
        "\n",
        "    def F(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential F(r) → 1 as r → ∞.\"\"\"\n",
        "        return 1.0 - torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def H(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential H(r) → 0 as r → ∞.\"\"\"\n",
        "        return torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def dF_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "    def dH_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return -torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "\n",
        "class TCSGeometry:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.n = config['n_grid']\n",
        "        tcs_cfg = config['tcs']\n",
        "\n",
        "        self.r_neck_start = tcs_cfg['r_neck_start']\n",
        "        self.r_neck_end = tcs_cfg['r_neck_end']\n",
        "        self.twist_angle = tcs_cfg['twist_angle']\n",
        "        self.neck_width = tcs_cfg.get('neck_width', 5.0)  # NEW v1.1: Extended neck\n",
        "\n",
        "        self.acyl = ACylPotentials(tcs_cfg['r_acyl_cutoff'])\n",
        "\n",
        "        self.coords = np.linspace(0, 1, self.n, endpoint=False)\n",
        "\n",
        "    def radial_coordinate(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Map T⁷ coordinate to radial parameter r ∈ [0,1].\"\"\"\n",
        "        return x[:, 0]\n",
        "\n",
        "    def region_classification(self, r: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"Classify points into M₁, Neck, M₂.\"\"\"\n",
        "        m1_mask = r < self.r_neck_start\n",
        "        neck_mask = (r >= self.r_neck_start) & (r <= self.r_neck_end)\n",
        "        m2_mask = r > self.r_neck_end\n",
        "\n",
        "        return {'M1': m1_mask, 'Neck': neck_mask, 'M2': m2_mask}\n",
        "    \n",
        "    def neck_profile(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        NEW v1.1: Extended Gaussian neck profile for RG flow accumulation.\n",
        "        \n",
        "        Args:\n",
        "            r: Radial coordinate\n",
        "            \n",
        "        Returns:\n",
        "            profile: Smooth interpolation across extended neck region\n",
        "        \"\"\"\n",
        "        r_center = (self.r_neck_start + self.r_neck_end) / 2\n",
        "        r_normalized = (r - r_center) / self.neck_width\n",
        "        \n",
        "        return torch.exp(-r_normalized**2 / 2)\n",
        "\n",
        "    def neck_interpolation(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Smooth interpolation χ: 0 in M₁, 1 in M₂.\n",
        "        NEW v1.1: Uses extended neck profile.\n",
        "        \"\"\"\n",
        "        r_norm = (r - self.r_neck_start) / (self.r_neck_end - self.r_neck_start)\n",
        "        r_norm = torch.clamp(r_norm, 0.0, 1.0)\n",
        "\n",
        "        # Extended neck modulation\n",
        "        profile = self.neck_profile(r)\n",
        "        chi = 3 * r_norm**2 - 2 * r_norm**3\n",
        "        \n",
        "        # Smooth transition influenced by extended profile\n",
        "        chi = chi * (1.0 + 0.5 * profile)\n",
        "        \n",
        "        return torch.clamp(chi, 0.0, 1.0)\n",
        "\n",
        "    def twist_map(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply twist ψ on neck cross-section S¹×S¹.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        chi = self.neck_interpolation(r)\n",
        "\n",
        "        x_twisted = x.clone()\n",
        "\n",
        "        theta1 = 2 * np.pi * x[:, 1]\n",
        "        theta2 = 2 * np.pi * x[:, 2]\n",
        "\n",
        "        theta1_new = theta1 + chi * self.twist_angle\n",
        "        theta2_new = theta2 - chi * self.twist_angle\n",
        "\n",
        "        x_twisted[:, 1] = (theta1_new / (2 * np.pi)) % 1.0\n",
        "        x_twisted[:, 2] = (theta2_new / (2 * np.pi)) % 1.0\n",
        "\n",
        "        return x_twisted\n",
        "\n",
        "    def acyl_metric_correction(self, x: torch.Tensor, g_base: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply ACyl corrections to metric.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        F = self.acyl.F(r).unsqueeze(-1).unsqueeze(-1)\n",
        "        H = self.acyl.H(r).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        g_corrected = g_base.clone()\n",
        "\n",
        "        g_corrected[regions['M1']] = g_base[regions['M1']] * (1.0 + 0.1 * H[regions['M1']])\n",
        "        g_corrected[regions['M2']] = g_base[regions['M2']] * (1.0 + 0.1 * H[regions['M2']])\n",
        "\n",
        "        return g_corrected\n",
        "\n",
        "    def compute_normal_derivative_mismatch(self, phi_net: nn.Module, coords: torch.Tensor, extd) -> torch.Tensor:\n",
        "        \"\"\"Compute ACyl normal derivative matching condition.\"\"\"\n",
        "        r = self.radial_coordinate(coords)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        if not (regions['M1'].any() or regions['M2'].any()):\n",
        "            return torch.tensor(0.0, device=coords.device)\n",
        "\n",
        "        epsilon = 1e-4\n",
        "        coords_plus = coords.clone()\n",
        "        coords_plus[:, 0] += epsilon\n",
        "        coords_plus[:, 0] = coords_plus[:, 0] % 1.0\n",
        "\n",
        "        coords_minus = coords.clone()\n",
        "        coords_minus[:, 0] -= epsilon\n",
        "        coords_minus[:, 0] = coords_minus[:, 0] % 1.0\n",
        "\n",
        "        phi = phi_net(coords)\n",
        "        phi_plus = phi_net(coords_plus)\n",
        "        phi_minus = phi_net(coords_minus)\n",
        "\n",
        "        dphi_dr = (phi_plus - phi_minus) / (2 * epsilon)\n",
        "\n",
        "        dF_dr = self.acyl.dF_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "        dH_dr = self.acyl.dH_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        expected_derivative = phi * (0.1 * dH_dr)\n",
        "\n",
        "        mismatch = torch.tensor(0.0, device=coords.device)\n",
        "        if regions['M1'].any():\n",
        "            mismatch += ((dphi_dr[regions['M1']] - expected_derivative[regions['M1']]) ** 2).mean()\n",
        "        if regions['M2'].any():\n",
        "            mismatch += ((dphi_dr[regions['M2']] - expected_derivative[regions['M2']]) ** 2).mean()\n",
        "\n",
        "        return mismatch\n",
        "\n",
        "geometry = TCSGeometry(CONFIG)\n",
        "print(f\"TCS regions: M₁ [0, {geometry.r_neck_start}], Neck [{geometry.r_neck_start}, {geometry.r_neck_end}], M₂ [{geometry.r_neck_end}, 1]\")\n",
        "print(f\"Twist angle: {geometry.twist_angle:.4f} rad\")\n",
        "print(f\"Extended neck width: σ_neck = {geometry.neck_width}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Enhanced φ-Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FourierEncoding(nn.Module):\n",
        "    def __init__(self, n_freqs: int):\n",
        "        super().__init__()\n",
        "        self.n_freqs = n_freqs\n",
        "        self.register_buffer('freqs', 2 ** torch.arange(n_freqs, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x_proj = 2 * np.pi * x.unsqueeze(-1) * self.freqs\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1).flatten(-2)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self.net(x)\n",
        "\n",
        "\n",
        "class PhiNetwork(nn.Module):\n",
        "    def __init__(self, config: Dict):\n",
        "        super().__init__()\n",
        "        self.n_freqs = config['n_fourier']\n",
        "        self.hidden = config['hidden_dim']\n",
        "        self.n_layers = config['n_layers']\n",
        "\n",
        "        self.encoding = FourierEncoding(self.n_freqs)\n",
        "        input_dim = 7 * 2 * self.n_freqs\n",
        "\n",
        "        self.input_proj = nn.Linear(input_dim, self.hidden)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ResidualBlock(self.hidden) for _ in range(self.n_layers)\n",
        "        ])\n",
        "\n",
        "        self.phi_head = nn.Sequential(\n",
        "            nn.Linear(self.hidden, self.hidden // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden // 2, 35)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x_enc = self.encoding(x)\n",
        "        h = self.input_proj(x_enc)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            h = block(h)\n",
        "\n",
        "        phi_flat = self.phi_head(h)\n",
        "\n",
        "        phi = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    val = phi_flat[:, idx]\n",
        "\n",
        "                    phi[:, i, j, k] = val\n",
        "                    phi[:, i, k, j] = -val\n",
        "                    phi[:, j, i, k] = -val\n",
        "                    phi[:, j, k, i] = val\n",
        "                    phi[:, k, i, j] = val\n",
        "                    phi[:, k, j, i] = -val\n",
        "\n",
        "                    idx += 1\n",
        "\n",
        "        return phi\n",
        "\n",
        "phi_net = PhiNetwork(CONFIG).to(device)\n",
        "print(f\"φ-network parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. G₂ Metric and Hodge Dual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_g2_metric(phi: torch.Tensor, epsilon: float = 1e-4, phase: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Compute G₂ metric g_{ij} = (1/6) φ_{ipq} φ_j^{pq}.\"\"\"\n",
        "    batch_size = phi.shape[0]\n",
        "    g = torch.zeros(batch_size, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            g[:, i, j] = (phi[:, i, :, :] * phi[:, j, :, :]).sum(dim=(-2, -1)) / 6.0\n",
        "\n",
        "    # Force exact symmetrization\n",
        "    g = (g + g.transpose(-2, -1)) / 2.0\n",
        "\n",
        "    # Phase-adaptive regularization\n",
        "    eps_adaptive = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "    eps = eps_adaptive.get(phase, epsilon)\n",
        "\n",
        "    eye = torch.eye(7, device=phi.device, dtype=phi.dtype).unsqueeze(0)\n",
        "    g = g + eps * eye\n",
        "\n",
        "    g_inv = torch.linalg.inv(g)\n",
        "\n",
        "    return g, g_inv\n",
        "\n",
        "\n",
        "def normalize_metric(g: torch.Tensor, target_det: float = 2.0) -> torch.Tensor:\n",
        "    \"\"\"Normalize metric to have det(g) = target_det.\"\"\"\n",
        "    det = torch.linalg.det(g)\n",
        "    scale = (target_det / det.abs().clamp(min=1e-8)) ** (1.0 / 7.0)\n",
        "    return g * scale.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "\n",
        "EPSILON_7D = None\n",
        "\n",
        "def compute_hodge_dual(phi: torch.Tensor, g: torch.Tensor, g_inv: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute ψ = *φ.\"\"\"\n",
        "    global EPSILON_7D\n",
        "    if EPSILON_7D is None:\n",
        "        from itertools import permutations\n",
        "        epsilon = torch.zeros(7, 7, 7, 7, 7, 7, 7)\n",
        "        base = list(range(7))\n",
        "        for perm in permutations(base):\n",
        "            sign = 1\n",
        "            temp = list(perm)\n",
        "            for i in range(7):\n",
        "                for j in range(i+1, 7):\n",
        "                    if temp[i] > temp[j]:\n",
        "                        sign *= -1\n",
        "            epsilon[perm] = sign\n",
        "        EPSILON_7D = epsilon.to(phi.device)\n",
        "\n",
        "    batch_size = phi.shape[0]\n",
        "    psi = torch.zeros(batch_size, 7, 7, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    det_g = torch.linalg.det(g)\n",
        "    sqrt_det = torch.sqrt(det_g.abs().clamp(min=1e-8))\n",
        "\n",
        "    phi_raised = torch.einsum('bijk,bil,bjm,bkn->blmn', phi, g_inv, g_inv, g_inv)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        psi[b] = torch.einsum('ijklmnp,mnp->ijkl', EPSILON_7D, phi_raised[b]) / (6.0 * sqrt_det[b])\n",
        "\n",
        "    return psi\n",
        "\n",
        "print(\"G₂ metric and Hodge dual ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exterior Derivatives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExteriorDerivative:\n",
        "    def __init__(self, n_grid: int, epsilon: float = 1e-4):\n",
        "        self.n = n_grid\n",
        "        self.dx = 1.0 / n_grid\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def compute_jacobian(self, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute Jacobian ∂φ_{ijk}/∂x^l.\"\"\"\n",
        "        batch_size = coords.shape[0]\n",
        "        jacobian = torch.zeros(batch_size, 7, 7, 7, 7, device=coords.device, dtype=coords.dtype)\n",
        "\n",
        "        for l in range(7):\n",
        "            coords_plus = coords.clone()\n",
        "            coords_plus[:, l] += self.epsilon\n",
        "            coords_plus[:, l] = coords_plus[:, l] % 1.0\n",
        "\n",
        "            coords_minus = coords.clone()\n",
        "            coords_minus[:, l] -= self.epsilon\n",
        "            coords_minus[:, l] = coords_minus[:, l] % 1.0\n",
        "\n",
        "            phi_plus = phi_net(coords_plus)\n",
        "            phi_minus = phi_net(coords_minus)\n",
        "\n",
        "            jacobian[:, :, :, :, l] = (phi_plus - phi_minus) / (2 * self.epsilon)\n",
        "\n",
        "        return jacobian\n",
        "\n",
        "    def d_phi(self, jacobian: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute dφ from Jacobian.\"\"\"\n",
        "        batch_size = jacobian.shape[0]\n",
        "        dphi = torch.zeros(batch_size, 7, 7, 7, 7, device=jacobian.device, dtype=jacobian.dtype)\n",
        "\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    for l in range(7):\n",
        "                        if l in {i, j, k}:\n",
        "                            continue\n",
        "\n",
        "                        val = (jacobian[:, j, k, l, i] -\n",
        "                               jacobian[:, i, k, l, j] +\n",
        "                               jacobian[:, i, j, l, k] -\n",
        "                               jacobian[:, i, j, k, l])\n",
        "\n",
        "                        indices = [i, j, k, l]\n",
        "                        for perm_idx, perm in enumerate([(0,1,2,3), (0,1,3,2), (0,2,1,3), (0,2,3,1)]):\n",
        "                            p = [indices[perm[m]] for m in range(4)]\n",
        "                            sign = 1\n",
        "                            for a in range(4):\n",
        "                                for b in range(a+1, 4):\n",
        "                                    if p[a] > p[b]:\n",
        "                                        sign *= -1\n",
        "                            dphi[:, p[0], p[1], p[2], p[3]] = sign * val\n",
        "\n",
        "        return dphi\n",
        "\n",
        "    def d_psi_norm(self, psi: torch.Tensor, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute ||dψ||.\"\"\"\n",
        "        jacobian = self.compute_jacobian(phi_net, coords)\n",
        "        dphi_norm = (jacobian ** 2).sum(dim=(-4, -3, -2, -1))\n",
        "        return torch.sqrt(dphi_norm.mean())\n",
        "\n",
        "extd = ExteriorDerivative(CONFIG['n_grid'])\n",
        "print(\"Exterior derivative operators ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. NEW v1.1: Torsion Targeting Loss (CRITICAL FIX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_torsion_targeting_loss(dphi: torch.Tensor, dpsi_norm: torch.Tensor, \n",
        "                                   target_torsion: float, config: Dict) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Target torsion magnitude rather than minimize to zero.\n",
        "    \n",
        "    This is the CRITICAL FIX for v1.1:\n",
        "    - v1.0f minimized: loss = ||dφ||² + ||dψ||² → drives torsion to machine precision\n",
        "    - v1.1 targets: loss = (||T|| - target)² → maintains phenomenologically viable torsion\n",
        "    \n",
        "    Args:\n",
        "        dphi: Exterior derivative tensor (batch, 7, 7, 7, 7)\n",
        "        dpsi_norm: Scalar norm of d*φ\n",
        "        target_torsion: Target ||T|| from GIFT calibration (phase-dependent)\n",
        "        config: Configuration dictionary\n",
        "    \n",
        "    Returns:\n",
        "        loss_torsion: Squared deviation from target\n",
        "        actual_torsion: Current torsion magnitude (for monitoring)\n",
        "    \"\"\"\n",
        "    # Compute actual torsion norm from dphi and dpsi\n",
        "    dphi_norm = torch.sqrt((dphi ** 2).sum(dim=(-4,-3,-2,-1)).mean())\n",
        "    actual_torsion = torch.sqrt(dphi_norm**2 + dpsi_norm**2)\n",
        "    \n",
        "    # Penalize deviation from target (not from zero)\n",
        "    loss_torsion = (actual_torsion - target_torsion)**2\n",
        "    \n",
        "    # Prevent collapse to zero (floor enforcement)\n",
        "    torsion_floor = config.get('torsion_floor', 1e-9)\n",
        "    if actual_torsion < torsion_floor:\n",
        "        loss_torsion += 100.0 * (torsion_floor - actual_torsion)\n",
        "    \n",
        "    return loss_torsion, actual_torsion\n",
        "\n",
        "\n",
        "print(\"Torsion targeting loss ready (v1.1 critical fix)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. NEW v1.1: AlphaInverseFunctional (Observable-Based Training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AlphaInverseFunctional(nn.Module):\n",
        "    \"\"\"\n",
        "    NEW v1.1: Compute α⁻¹ as functional of geometry.\n",
        "    \n",
        "    α⁻¹(x) = α⁻¹_ref + A·δ(det g) + B·δ||T|| + Σ C_i·δT^{components}\n",
        "    \n",
        "    This functional explicitly depends on torsion magnitude, creating physics-based\n",
        "    constraint that maintains ||T|| ≠ 0 for phenomenological viability.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, config: Dict):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Reference values (M_Z scale)\n",
        "        self.alpha_inv_ref = 137.036  # QED fine structure constant\n",
        "        self.det_g_ref = config['target']['det_g']\n",
        "        self.T_norm_ref = config['target']['torsion_norm']\n",
        "        \n",
        "        # Learnable coefficients (calibrated globally at epoch 6000)\n",
        "        # Initial values from toy model validation\n",
        "        self.A = nn.Parameter(torch.tensor(-4.68))  # det(g) coefficient\n",
        "        self.B = nn.Parameter(torch.tensor(15.17))  # torsion norm coefficient\n",
        "        self.C = nn.Parameter(torch.tensor([10.0, 5.0, 1.0]))  # component coefficients\n",
        "        \n",
        "    def forward(self, g: torch.Tensor, T: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            g: Metric tensor (batch, 7, 7)\n",
        "            T: Torsion tensor (batch, 7, 7, 7) - this is dphi in our case\n",
        "            \n",
        "        Returns:\n",
        "            alpha_inv: (batch,) - fine structure constant at each point\n",
        "        \"\"\"\n",
        "        det_g = torch.linalg.det(g)\n",
        "        T_norm = torch.sqrt((T**2).sum(dim=(-3,-2,-1)))\n",
        "        \n",
        "        # Key torsion components (indices: electron, pion, photon)\n",
        "        # These specific components couple to fermion mass generation\n",
        "        T_components = torch.stack([\n",
        "            T[:, 1, 0, 2],  # T^π_{eφ}\n",
        "            T[:, 0, 1, 2],  # T^e_{πφ}\n",
        "            T[:, 2, 0, 1]   # T^φ_{eπ}\n",
        "        ], dim=-1)\n",
        "        \n",
        "        # Deviations from reference\n",
        "        delta_det_g = det_g - self.det_g_ref\n",
        "        delta_T_norm = T_norm - self.T_norm_ref\n",
        "        delta_T_components = T_components  # Already relative\n",
        "        \n",
        "        # Functional\n",
        "        alpha_inv = self.alpha_inv_ref\n",
        "        alpha_inv = alpha_inv + self.A * delta_det_g\n",
        "        alpha_inv = alpha_inv + self.B * delta_T_norm\n",
        "        alpha_inv = alpha_inv + torch.sum(self.C * delta_T_components, dim=-1)\n",
        "        \n",
        "        return alpha_inv\n",
        "\n",
        "\n",
        "alpha_functional = AlphaInverseFunctional(CONFIG).to(device)\n",
        "print(f\"AlphaInverseFunctional initialized\")\n",
        "print(f\"  Reference α⁻¹ = {alpha_functional.alpha_inv_ref}\")\n",
        "print(f\"  Initial coefficients: A={alpha_functional.A.item():.2f}, B={alpha_functional.B.item():.2f}\")\n",
        "print(f\"  Component weights: C={alpha_functional.C.data.cpu().numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. NEW v1.1: Geodesic Integrator for RG Flow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GeodesicIntegrator:\n",
        "    \"\"\"\n",
        "    NEW v1.1: RK4/5 integrator with cached Christoffel symbols for geodesic integration.\n",
        "    \n",
        "    Integrates geodesic equation: d²x/dλ² + Γ^i_jk (dx/dλ)^j (dx/dλ)^k = 0\n",
        "    \n",
        "    Used for RG flow: integrate from M_Z (initial) to M_Planck (final) along\n",
        "    quasi-static trajectory in moduli space.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, phi_net: nn.Module, geometry: TCSGeometry, config: Dict):\n",
        "        self.phi_net = phi_net\n",
        "        self.geometry = geometry\n",
        "        self.config = config\n",
        "        self.christoffel_cache = {}  # Cache for computed Christoffel symbols\n",
        "        \n",
        "    def compute_christoffel(self, x: torch.Tensor, g: torch.Tensor, g_inv: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute Christoffel symbols Γ^i_jk = (1/2) g^il (∂_j g_lk + ∂_k g_jl - ∂_l g_jk).\n",
        "        \n",
        "        Args:\n",
        "            x: Position (batch, 7)\n",
        "            g: Metric (batch, 7, 7)\n",
        "            g_inv: Inverse metric (batch, 7, 7)\n",
        "            \n",
        "        Returns:\n",
        "            christoffel: (batch, 7, 7, 7) - Γ^i_jk\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        christoffel = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "        \n",
        "        epsilon = 1e-4\n",
        "        \n",
        "        # Compute metric derivatives numerically\n",
        "        for l in range(7):\n",
        "            x_plus = x.clone()\n",
        "            x_plus[:, l] += epsilon\n",
        "            x_plus[:, l] = x_plus[:, l] % 1.0\n",
        "            \n",
        "            x_minus = x.clone()\n",
        "            x_minus[:, l] -= epsilon\n",
        "            x_minus[:, l] = x_minus[:, l] % 1.0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                phi_plus = self.phi_net(x_plus)\n",
        "                phi_minus = self.phi_net(x_minus)\n",
        "                \n",
        "                g_plus, _ = compute_g2_metric(phi_plus, phase=5)\n",
        "                g_minus, _ = compute_g2_metric(phi_minus, phase=5)\n",
        "                \n",
        "                g_plus = self.geometry.acyl_metric_correction(x_plus, g_plus)\n",
        "                g_minus = self.geometry.acyl_metric_correction(x_minus, g_minus)\n",
        "                \n",
        "                dg_dl = (g_plus - g_minus) / (2 * epsilon)\n",
        "            \n",
        "            # Compute Christoffel components\n",
        "            for i in range(7):\n",
        "                for j in range(7):\n",
        "                    for k in range(7):\n",
        "                        val = 0.5 * (dg_dl[:, i, k] + dg_dl[:, i, j] - dg_dl[:, j, k])\n",
        "                        christoffel[:, :, j, k] += g_inv[:, :, i].unsqueeze(-1).unsqueeze(-1) * val.unsqueeze(1)\n",
        "        \n",
        "        return christoffel\n",
        "    \n",
        "    def geodesic_rhs(self, x: torch.Tensor, v: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Right-hand side of geodesic equation.\n",
        "        \n",
        "        dx/dλ = v\n",
        "        dv/dλ = -Γ^i_jk v^j v^k\n",
        "        \n",
        "        Args:\n",
        "            x: Position (batch, 7)\n",
        "            v: Velocity (batch, 7)\n",
        "            \n",
        "        Returns:\n",
        "            dx/dλ, dv/dλ\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            phi = self.phi_net(x)\n",
        "            g, g_inv = compute_g2_metric(phi, phase=5)\n",
        "            g = self.geometry.acyl_metric_correction(x, g)\n",
        "            g = normalize_metric(g, self.config['target']['det_g'])\n",
        "            \n",
        "            christoffel = self.compute_christoffel(x, g, g_inv)\n",
        "            \n",
        "            # dv/dλ = -Γ^i_jk v^j v^k\n",
        "            dv = -torch.einsum('bijk,bj,bk->bi', christoffel, v, v)\n",
        "            \n",
        "        return v, dv\n",
        "    \n",
        "    def integrate_rk4(self, x0: torch.Tensor, v0: torch.Tensor, lambda_max: float, n_steps: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        RK4 integration of geodesic from λ=0 to λ=lambda_max.\n",
        "        \n",
        "        Args:\n",
        "            x0: Initial position (7,)\n",
        "            v0: Initial velocity (7,)\n",
        "            lambda_max: Maximum affine parameter (ln(M_Planck/M_Z) = 39.44)\n",
        "            n_steps: Number of integration steps\n",
        "            \n",
        "        Returns:\n",
        "            x_trajectory: (n_steps+1, 7) - positions along geodesic\n",
        "            v_trajectory: (n_steps+1, 7) - velocities along geodesic\n",
        "        \"\"\"\n",
        "        dlambda = lambda_max / n_steps\n",
        "        \n",
        "        x_traj = [x0.unsqueeze(0)]\n",
        "        v_traj = [v0.unsqueeze(0)]\n",
        "        \n",
        "        x = x0.unsqueeze(0)\n",
        "        v = v0.unsqueeze(0)\n",
        "        \n",
        "        for step in range(n_steps):\n",
        "            # RK4 integration\n",
        "            k1_x, k1_v = self.geodesic_rhs(x, v)\n",
        "            \n",
        "            k2_x, k2_v = self.geodesic_rhs(x + 0.5 * dlambda * k1_x, v + 0.5 * dlambda * k1_v)\n",
        "            \n",
        "            k3_x, k3_v = self.geodesic_rhs(x + 0.5 * dlambda * k2_x, v + 0.5 * dlambda * k2_v)\n",
        "            \n",
        "            k4_x, k4_v = self.geodesic_rhs(x + dlambda * k3_x, v + dlambda * k3_v)\n",
        "            \n",
        "            # Update\n",
        "            x = x + (dlambda / 6.0) * (k1_x + 2*k2_x + 2*k3_x + k4_x)\n",
        "            v = v + (dlambda / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)\n",
        "            \n",
        "            # Periodic boundary conditions\n",
        "            x = x % 1.0\n",
        "            \n",
        "            x_traj.append(x)\n",
        "            v_traj.append(v)\n",
        "        \n",
        "        x_trajectory = torch.cat(x_traj, dim=0)\n",
        "        v_trajectory = torch.cat(v_traj, dim=0)\n",
        "        \n",
        "        return x_trajectory, v_trajectory\n",
        "\n",
        "\n",
        "geodesic_integrator = GeodesicIntegrator(phi_net, geometry, CONFIG)\n",
        "print(\"Geodesic integrator ready (RK4 with Christoffel computation)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. NEW v1.1: RG Flow Loss and Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_rg_flow_loss(phi_net: nn.Module, alpha_functional: AlphaInverseFunctional,\n",
        "                         geodesic_integrator: GeodesicIntegrator, config: Dict) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Compute RG flow constraint loss.\n",
        "    \n",
        "    Integrates geodesic from M_Z to M_Planck and computes Δα⁻¹.\n",
        "    Loss = (Δα⁻¹ - target_delta_alpha)²\n",
        "    \n",
        "    Args:\n",
        "        phi_net: Neural network for φ\n",
        "        alpha_functional: Observable functional\n",
        "        geodesic_integrator: Geodesic integrator\n",
        "        config: Configuration dictionary\n",
        "        \n",
        "    Returns:\n",
        "        loss_rg: RG flow loss\n",
        "    \"\"\"\n",
        "    rg_config = config['rg_flow']\n",
        "    \n",
        "    # Initial conditions: start at origin with small velocity in neck direction\n",
        "    x0 = torch.zeros(7, device=device)\n",
        "    v0 = torch.tensor([0, -1e-3, 0, 0, 0, 0, 0], device=device, dtype=torch.float32)\n",
        "    \n",
        "    # Integrate geodesic\n",
        "    x_traj, v_traj = geodesic_integrator.integrate_rk4(\n",
        "        x0, v0, \n",
        "        rg_config['lambda_max'], \n",
        "        rg_config['n_integration_steps']\n",
        "    )\n",
        "    \n",
        "    # Compute α⁻¹ at start and end\n",
        "    with torch.no_grad():\n",
        "        # Start point (M_Z)\n",
        "        phi_start = phi_net(x_traj[0:1])\n",
        "        g_start, g_inv_start = compute_g2_metric(phi_start, phase=5)\n",
        "        g_start = geodesic_integrator.geometry.acyl_metric_correction(x_traj[0:1], g_start)\n",
        "        g_start = normalize_metric(g_start, config['target']['det_g'])\n",
        "        \n",
        "        jacobian_start = extd.compute_jacobian(phi_net, x_traj[0:1])\n",
        "        dphi_start = extd.d_phi(jacobian_start)\n",
        "        \n",
        "        alpha_start = alpha_functional(g_start, dphi_start)\n",
        "        \n",
        "        # End point (M_Planck)\n",
        "        phi_end = phi_net(x_traj[-1:])\n",
        "        g_end, g_inv_end = compute_g2_metric(phi_end, phase=5)\n",
        "        g_end = geodesic_integrator.geometry.acyl_metric_correction(x_traj[-1:], g_end)\n",
        "        g_end = normalize_metric(g_end, config['target']['det_g'])\n",
        "        \n",
        "        jacobian_end = extd.compute_jacobian(phi_net, x_traj[-1:])\n",
        "        dphi_end = extd.d_phi(jacobian_end)\n",
        "        \n",
        "        alpha_end = alpha_functional(g_end, dphi_end)\n",
        "    \n",
        "    # Compute Δα⁻¹\n",
        "    delta_alpha = alpha_end - alpha_start\n",
        "    \n",
        "    # Loss: match QED running\n",
        "    target_delta = rg_config['target_delta_alpha']\n",
        "    loss_rg = (delta_alpha - target_delta) ** 2\n",
        "    \n",
        "    return loss_rg.mean()\n",
        "\n",
        "\n",
        "def calibrate_coefficients_global(phi_net: nn.Module, x0: torch.Tensor, v0: torch.Tensor,\n",
        "                                  lambda_max: float, target_delta_alpha: float,\n",
        "                                  n_samples: int = 50) -> Dict:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Calibrate AlphaInverseFunctional coefficients globally.\n",
        "    \n",
        "    Fits A, B coefficients to match target Δα⁻¹ over multiple trajectories.\n",
        "    \n",
        "    Args:\n",
        "        phi_net: Neural network\n",
        "        x0: Initial position\n",
        "        v0: Initial velocity\n",
        "        lambda_max: Integration range\n",
        "        target_delta_alpha: Target RG running (-0.9 for QED)\n",
        "        n_samples: Number of sample points along trajectory\n",
        "        \n",
        "    Returns:\n",
        "        coeffs: Dictionary with calibrated A, B values\n",
        "    \"\"\"\n",
        "    print(\"Calibrating RG flow coefficients...\")\n",
        "    \n",
        "    # Integrate reference trajectory\n",
        "    integrator = GeodesicIntegrator(phi_net, geometry, CONFIG)\n",
        "    x_traj, v_traj = integrator.integrate_rk4(x0, v0, lambda_max, 100)\n",
        "    \n",
        "    # Sample points along trajectory\n",
        "    sample_indices = torch.linspace(0, len(x_traj)-1, n_samples, dtype=torch.long)\n",
        "    \n",
        "    det_g_vals = []\n",
        "    T_norm_vals = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx in sample_indices:\n",
        "            x_sample = x_traj[idx:idx+1]\n",
        "            \n",
        "            phi = phi_net(x_sample)\n",
        "            g, _ = compute_g2_metric(phi, phase=5)\n",
        "            g = geometry.acyl_metric_correction(x_sample, g)\n",
        "            g = normalize_metric(g, CONFIG['target']['det_g'])\n",
        "            \n",
        "            jacobian = extd.compute_jacobian(phi_net, x_sample)\n",
        "            dphi = extd.d_phi(jacobian)\n",
        "            \n",
        "            det_g = torch.linalg.det(g)\n",
        "            T_norm = torch.sqrt((dphi**2).sum(dim=(-4,-3,-2,-1)))\n",
        "            \n",
        "            det_g_vals.append(det_g.item())\n",
        "            T_norm_vals.append(T_norm.item())\n",
        "    \n",
        "    # Compute deltas\n",
        "    delta_det_g = det_g_vals[-1] - det_g_vals[0]\n",
        "    delta_T_norm = T_norm_vals[-1] - T_norm_vals[0]\n",
        "    \n",
        "    # Solve for coefficients (simple 2-parameter fit)\n",
        "    # Δα⁻¹ = A·Δ(det g) + B·Δ||T||\n",
        "    # Given target_delta_alpha, solve for A, B with minimal norm\n",
        "    \n",
        "    if abs(delta_T_norm) > 1e-8:\n",
        "        B = target_delta_alpha / delta_T_norm\n",
        "        A = 0.0  # Minimize norm: set A to zero if T provides sufficient signal\n",
        "    else:\n",
        "        B = 15.17  # Default from toy model\n",
        "        A = -4.68\n",
        "    \n",
        "    print(f\"  Calibrated coefficients: A={A:.4f}, B={B:.4f}\")\n",
        "    print(f\"  Δ(det g) = {delta_det_g:.6f}, Δ||T|| = {delta_T_norm:.6f}\")\n",
        "    print(f\"  Predicted Δα⁻¹ = {A*delta_det_g + B*delta_T_norm:.4f} (target: {target_delta_alpha:.4f})\")\n",
        "    \n",
        "    return {'A': A, 'B': B}\n",
        "\n",
        "\n",
        "print(\"RG flow loss and calibration routines ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Discrete Laplacian and Live Harmonic Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiscreteLaplacian:\n",
        "    def __init__(self, n_grid: int, dim: int):\n",
        "        self.n = n_grid\n",
        "        self.dim = dim\n",
        "        self.dx = 1.0 / n_grid\n",
        "\n",
        "        from scipy.special import comb\n",
        "        self.n_dof = int(comb(7, dim)) * (n_grid ** 7)\n",
        "\n",
        "        print(f\"Building {dim}-form Laplacian: {self.n}^7 = {self.n**7:,} points...\")\n",
        "        self.laplacian = self._build_laplacian_fast()\n",
        "\n",
        "    def _build_laplacian_fast(self) -> csr_matrix:\n",
        "        \"\"\"Vectorized Laplacian construction.\"\"\"\n",
        "        n = self.n\n",
        "        n_total = n ** 7\n",
        "\n",
        "        print(f\"  Allocating sparse structure for {n_total:,} × {n_total:,} matrix...\")\n",
        "\n",
        "        # Pre-allocate arrays for COO format\n",
        "        max_entries = n_total * (1 + 2 * 7)\n",
        "        row_indices = []\n",
        "        col_indices = []\n",
        "        data = []\n",
        "\n",
        "        stencil = -2.0 * 7 / (self.dx ** 2)\n",
        "        neighbor = 1.0 / (self.dx ** 2)\n",
        "\n",
        "        # Diagonal entries\n",
        "        print(f\"  Building diagonal...\")\n",
        "        diag_idx = np.arange(n_total)\n",
        "        row_indices.append(diag_idx)\n",
        "        col_indices.append(diag_idx)\n",
        "        data.append(np.full(n_total, stencil))\n",
        "\n",
        "        # Off-diagonal entries (vectorized by axis)\n",
        "        print(f\"  Building off-diagonal entries...\")\n",
        "        for axis in range(7):\n",
        "            if axis % 2 == 0:\n",
        "                print(f\"    Processing axis {axis+1}/7...\")\n",
        "\n",
        "            # Compute all indices at once\n",
        "            all_coords = np.array(np.unravel_index(np.arange(n_total), [n] * 7))\n",
        "\n",
        "            # Forward neighbors\n",
        "            coords_plus = all_coords.copy()\n",
        "            coords_plus[axis] = (coords_plus[axis] + 1) % n\n",
        "            idx_plus = np.ravel_multi_index(coords_plus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_plus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "            # Backward neighbors\n",
        "            coords_minus = all_coords.copy()\n",
        "            coords_minus[axis] = (coords_minus[axis] - 1) % n\n",
        "            idx_minus = np.ravel_multi_index(coords_minus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_minus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "        # Concatenate all arrays\n",
        "        print(f\"  Assembling sparse matrix...\")\n",
        "        row_indices = np.concatenate(row_indices)\n",
        "        col_indices = np.concatenate(col_indices)\n",
        "        data = np.concatenate(data)\n",
        "\n",
        "        # Build COO then convert to CSR\n",
        "        from scipy.sparse import coo_matrix\n",
        "        L = coo_matrix((data, (row_indices, col_indices)), shape=(n_total, n_total))\n",
        "        print(f\"  Converting to CSR format...\")\n",
        "        L_csr = L.tocsr()\n",
        "        print(f\"  ✓ Laplacian built: {L_csr.nnz:,} non-zero entries\")\n",
        "\n",
        "        return L_csr\n",
        "\n",
        "    def compute_spectrum(self, k: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Extract k smallest eigenvalues/vectors.\"\"\"\n",
        "        print(f\"  Computing {k} smallest eigenmodes (this may take 5-15 min)...\")\n",
        "        import time\n",
        "        start = time.time()\n",
        "\n",
        "        # Limit k to avoid convergence issues\n",
        "        k_safe = min(k, self.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = eigsh(self.laplacian, k=k_safe, which='SM',\n",
        "                                          tol=1e-5, maxiter=1000)\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"  ✓ Spectrum computed in {elapsed/60:.1f} minutes\")\n",
        "\n",
        "        return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "class LiveHarmonicExtractor:\n",
        "    def __init__(self, laplacian: DiscreteLaplacian, target_dim: int, threshold: float = 1e-6):\n",
        "        self.laplacian = laplacian\n",
        "        self.target_dim = target_dim\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def extract(self) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Extract harmonic modes and return (modes, effective_dimension).\"\"\"\n",
        "        k = min(self.target_dim + 50, self.laplacian.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = self.laplacian.compute_spectrum(k=k)\n",
        "\n",
        "        print(f\"  Eigenvalue range: [{eigenvalues[0]:.2e}, {eigenvalues[-1]:.2e}]\")\n",
        "\n",
        "        harmonic_mask = np.abs(eigenvalues) < self.threshold\n",
        "        harmonic_indices = np.where(harmonic_mask)[0]\n",
        "\n",
        "        print(f\"  Found {len(harmonic_indices)} harmonic modes (threshold={self.threshold:.2e})\")\n",
        "\n",
        "        if len(harmonic_indices) < self.target_dim:\n",
        "            print(f\"  ⚠ Using {self.target_dim} smallest modes instead\")\n",
        "            harmonic_indices = np.arange(min(self.target_dim, len(eigenvalues)))\n",
        "        else:\n",
        "            harmonic_indices = harmonic_indices[:self.target_dim]\n",
        "\n",
        "        harmonic_modes = eigenvectors[:, harmonic_indices]\n",
        "\n",
        "        Q, R = np.linalg.qr(harmonic_modes)\n",
        "\n",
        "        b_eff = len(harmonic_indices)\n",
        "\n",
        "        return Q, b_eff\n",
        "\n",
        "print(\"Discrete Laplacian and live harmonic extractor ready (optimized version)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Complete Loss Function with Torsion Targeting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_complete_loss(phi_net: nn.Module, coords: torch.Tensor, geometry: TCSGeometry,\n",
        "                         extd: ExteriorDerivative, config: Dict, phase_weights: Dict,\n",
        "                         alpha_functional: Optional[AlphaInverseFunctional] = None,\n",
        "                         geodesic_integrator: Optional[GeodesicIntegrator] = None,\n",
        "                         harmonic_extractors: Optional[Dict] = None, phase: int = 1) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Complete multi-component loss with torsion targeting (not minimization).\n",
        "    \n",
        "    Key changes from v1.0f:\n",
        "    - Torsion: target specific magnitude (phase-dependent) instead of minimize to zero\n",
        "    - RG flow: add geodesic integration constraint in Phases 4-5\n",
        "    - Early stopping: phase-specific criteria for systematic convergence\n",
        "    \"\"\"\n",
        "    w = phase_weights\n",
        "    target = config['target']\n",
        "    target_torsion = config['torsion_targets'][phase]\n",
        "\n",
        "    phi = phi_net(coords)\n",
        "    g, g_inv = compute_g2_metric(phi, phase=phase)\n",
        "\n",
        "    g = geometry.acyl_metric_correction(coords, g)\n",
        "    g = normalize_metric(g, target['det_g'])\n",
        "\n",
        "    psi = compute_hodge_dual(phi, g, g_inv)\n",
        "\n",
        "    jacobian = extd.compute_jacobian(phi_net, coords)\n",
        "    dphi = extd.d_phi(jacobian)\n",
        "    dpsi_norm = extd.d_psi_norm(psi, phi_net, coords)\n",
        "\n",
        "    # NEW v1.1: Torsion targeting (critical fix)\n",
        "    loss_torsion, actual_torsion = compute_torsion_targeting_loss(dphi, dpsi_norm, target_torsion, config)\n",
        "\n",
        "    # Determinant constraint\n",
        "    det_g = torch.linalg.det(g)\n",
        "    loss_det = ((det_g - target['det_g']) ** 2).mean()\n",
        "\n",
        "    # Positivity with robust eigenvalue computation\n",
        "    try:\n",
        "        g_sym = (g + g.transpose(-2, -1)) / 2.0\n",
        "        floor_eps = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "        g_sym = g_sym + floor_eps.get(phase, 1e-5) * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        eigvals = torch.linalg.eigvalsh(g_sym)\n",
        "        loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "    except:\n",
        "        g_regularized = g + 1e-2 * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        g_regularized = (g_regularized + g_regularized.transpose(-2, -1)) / 2.0\n",
        "        try:\n",
        "            eigvals = torch.linalg.eigvalsh(g_regularized)\n",
        "            loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "        except:\n",
        "            eigvals = torch.ones(g.shape[0], 7, device=g.device) * 0.1\n",
        "            loss_positivity = torch.tensor(100.0, device=g.device)\n",
        "\n",
        "    eig_floor_threshold = {1: 3e-3, 2: 2e-3, 3: 1e-3, 4: 1e-4, 5: 1e-5}\n",
        "    threshold = eig_floor_threshold.get(phase, 1e-4)\n",
        "    loss_eig_floor = torch.relu(threshold - eigvals.min(dim=-1)[0]).mean()\n",
        "\n",
        "    r = geometry.radial_coordinate(coords)\n",
        "    regions = geometry.region_classification(r)\n",
        "\n",
        "    # Neck matching\n",
        "    loss_neck_match = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['Neck'].any():\n",
        "        coords_neck = coords[regions['Neck']]\n",
        "        coords_twisted = geometry.twist_map(coords_neck)\n",
        "\n",
        "        phi_neck = phi_net(coords_neck)\n",
        "        phi_twisted = phi_net(coords_twisted)\n",
        "\n",
        "        loss_neck_match = ((phi_neck - phi_twisted) ** 2).mean()\n",
        "\n",
        "    # ACyl matching\n",
        "    loss_acyl = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['M1'].any() or regions['M2'].any():\n",
        "        r_acyl = torch.cat([r[regions['M1']], r[regions['M2']]]) if regions['M1'].any() and regions['M2'].any() else (r[regions['M1']] if regions['M1'].any() else r[regions['M2']])\n",
        "        F = geometry.acyl.F(r_acyl)\n",
        "        H = geometry.acyl.H(r_acyl)\n",
        "\n",
        "        loss_acyl = ((F - 1.0) ** 2).mean() + (H ** 2).mean()\n",
        "\n",
        "        loss_acyl_derivatives = geometry.compute_normal_derivative_mismatch(phi_net, coords, extd)\n",
        "        loss_acyl = loss_acyl + loss_acyl_derivatives\n",
        "\n",
        "    # Harmonicity\n",
        "    loss_harmonicity = torch.tensor(0.0, device=coords.device)\n",
        "    if harmonic_extractors is not None and w['harmonicity'] > 0:\n",
        "        sample_size = min(256, coords.shape[0])\n",
        "        coords_sample = coords[:sample_size]\n",
        "\n",
        "        phi_sample = phi_net(coords_sample)\n",
        "        phi_flat = phi_sample.flatten(start_dim=1)\n",
        "\n",
        "        target_rank_2 = target['b2']\n",
        "\n",
        "        U, S, Vh = torch.linalg.svd(phi_flat, full_matrices=False)\n",
        "\n",
        "        if S.shape[0] > target_rank_2:\n",
        "            loss_harmonicity = loss_harmonicity + S[target_rank_2:].pow(2).sum()\n",
        "\n",
        "        eigenvalue_penalty = torch.tensor(0.0, device=coords.device)\n",
        "        if len(S) >= target_rank_2:\n",
        "            eigenvalue_penalty = torch.relu(config['torsion_threshold'] - S[:target_rank_2].min())\n",
        "\n",
        "        loss_harmonicity = loss_harmonicity + 10.0 * eigenvalue_penalty\n",
        "\n",
        "    # NEW v1.1: RG flow loss (Phases 4-5 only, computed stochastically)\n",
        "    loss_rg = torch.tensor(0.0, device=coords.device)\n",
        "    if phase >= 4 and w['rg_flow'] > 0 and alpha_functional is not None and geodesic_integrator is not None:\n",
        "        # Compute on 10% of batches for memory efficiency\n",
        "        if torch.rand(1).item() < config['rg_flow']['geodesic_batch_freq']:\n",
        "            loss_rg = compute_rg_flow_loss(phi_net, alpha_functional, geodesic_integrator, config)\n",
        "\n",
        "    w_eig_floor = {1: 1.5, 2: 0.8, 3: 0.3, 4: 0.05, 5: 0.01}\n",
        "    eig_weight = w_eig_floor.get(phase, 0.1)\n",
        "\n",
        "    total_loss = (w['torsion'] * loss_torsion +\n",
        "                  w['det'] * loss_det +\n",
        "                  w['positivity'] * loss_positivity +\n",
        "                  w['neck_match'] * loss_neck_match +\n",
        "                  w['acyl'] * loss_acyl +\n",
        "                  w['harmonicity'] * loss_harmonicity +\n",
        "                  w['rg_flow'] * loss_rg +\n",
        "                  eig_weight * loss_eig_floor)\n",
        "\n",
        "    # NaN guard\n",
        "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
        "        print(f\"NaN detected! Phase {phase}\")\n",
        "        total_loss = torch.tensor(1000.0, device=coords.device, requires_grad=True)\n",
        "\n",
        "    return {\n",
        "        'total': total_loss,\n",
        "        'torsion': loss_torsion,\n",
        "        'actual_torsion': actual_torsion,  # NEW: for monitoring\n",
        "        'det': loss_det,\n",
        "        'positivity': loss_positivity,\n",
        "        'neck_match': loss_neck_match,\n",
        "        'acyl': loss_acyl,\n",
        "        'harmonicity': loss_harmonicity,\n",
        "        'rg_flow': loss_rg,  # NEW\n",
        "        'eig_floor': loss_eig_floor\n",
        "    }\n",
        "\n",
        "print(\"Complete loss function ready (v1.1 with torsion targeting and RG flow)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Checkpoint Manager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CheckpointManager:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.checkpoint_dir = Path(config['checkpoint_dir'])\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "        self.freq = config['checkpoint_freq']\n",
        "\n",
        "    def save(self, phase: int, epoch: int, model: nn.Module, optimizer: optim.Optimizer,\n",
        "             loss_history: list, metadata: Dict):\n",
        "        checkpoint = {\n",
        "            'phase': phase,\n",
        "            'epoch': epoch,\n",
        "            'model_state': model.state_dict(),\n",
        "            'optimizer_state': optimizer.state_dict(),\n",
        "            'loss_history': loss_history,\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        path = self.checkpoint_dir / f'checkpoint_phase{phase}_epoch_{epoch}.pt'\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        config_path = self.checkpoint_dir / 'config.json'\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(metadata.get('config', {}), f, indent=2)\n",
        "\n",
        "    def load_latest(self) -> Optional[Dict]:\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "\n",
        "        if latest_path.exists():\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            return checkpoint\n",
        "\n",
        "        return None\n",
        "\n",
        "    def should_save(self, epoch: int) -> bool:\n",
        "        return (epoch + 1) % self.freq == 0\n",
        "\n",
        "checkpoint_mgr = CheckpointManager(CONFIG)\n",
        "print(f\"Checkpoint manager: {checkpoint_mgr.checkpoint_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. NEW v1.1: Multi-Phase Training with Systematic Early Stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_phase_early_stop(losses_dict: Dict, phase_config: Dict, phase_history: list, config: Dict) -> bool:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Check phase-specific early stopping criteria.\n",
        "    \n",
        "    Each phase has its own convergence criteria to prevent over-optimization\n",
        "    that could degrade subsequent phases.\n",
        "    \n",
        "    Args:\n",
        "        losses_dict: Current loss values\n",
        "        phase_config: Phase configuration with early_stop criteria\n",
        "        phase_history: Recent loss history for this phase\n",
        "        config: Global configuration\n",
        "        \n",
        "    Returns:\n",
        "        should_stop: Whether to stop this phase early\n",
        "    \"\"\"\n",
        "    if 'early_stop' not in phase_config:\n",
        "        return False\n",
        "    \n",
        "    early_stop_config = phase_config['early_stop']\n",
        "    patience = early_stop_config['patience']\n",
        "    criteria = early_stop_config['criteria']\n",
        "    \n",
        "    # Need sufficient history\n",
        "    if len(phase_history) < patience:\n",
        "        return False\n",
        "    \n",
        "    # Check if all criteria satisfied for patience epochs\n",
        "    recent_history = phase_history[-patience:]\n",
        "    \n",
        "    all_satisfied = True\n",
        "    for criterion_name, threshold in criteria.items():\n",
        "        if criterion_name == 'torsion_target_reached':\n",
        "            # Check if torsion is within 20% of target\n",
        "            if threshold:\n",
        "                for hist_entry in recent_history:\n",
        "                    actual_torsion = hist_entry.get('actual_torsion', 0)\n",
        "                    phase = hist_entry.get('phase', 1)\n",
        "                    target_torsion = config['torsion_targets'][phase]\n",
        "                    error = abs(actual_torsion - target_torsion) / target_torsion\n",
        "                    if error > 0.2:  # More than 20% error\n",
        "                        all_satisfied = False\n",
        "                        break\n",
        "        else:\n",
        "            # Standard threshold check\n",
        "            for hist_entry in recent_history:\n",
        "                if hist_entry.get(criterion_name, float('inf')) > threshold:\n",
        "                    all_satisfied = False\n",
        "                    break\n",
        "        \n",
        "        if not all_satisfied:\n",
        "            break\n",
        "    \n",
        "    return all_satisfied\n",
        "\n",
        "\n",
        "def train_multiphase(phi_net: nn.Module, geometry: TCSGeometry, extd: ExteriorDerivative,\n",
        "                     config: Dict, checkpoint_mgr: CheckpointManager,\n",
        "                     alpha_functional: AlphaInverseFunctional,\n",
        "                     geodesic_integrator: GeodesicIntegrator):\n",
        "    \"\"\"\n",
        "    NEW v1.1: Multi-phase curriculum training with:\n",
        "    - Systematic per-phase early stopping\n",
        "    - RG flow coefficient calibration at epoch 6000\n",
        "    - Torsion targeting (not minimization)\n",
        "    - Observable-based constraints\n",
        "    \"\"\"\n",
        "\n",
        "    import time\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    optimizer = optim.AdamW(phi_net.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n",
        "\n",
        "    start_phase = 1\n",
        "    start_epoch = 0\n",
        "    loss_history = []\n",
        "\n",
        "    checkpoint = checkpoint_mgr.load_latest()\n",
        "    if checkpoint is not None:\n",
        "        phi_net.load_state_dict(checkpoint['model_state'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "        start_phase = checkpoint['phase']\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        loss_history = checkpoint['loss_history']\n",
        "        print(f\"Resumed from Phase {checkpoint['phase']}, Epoch {checkpoint['epoch']}\")\n",
        "\n",
        "    n_epochs_per_phase = config['n_epochs_per_phase']\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    harmonic_extractors = {}\n",
        "\n",
        "    for phase in range(start_phase, len(config['phases']) + 1):\n",
        "        phase_config = config['phases'][phase]\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE {phase}: {phase_config['name']}\")\n",
        "        print(f\"Torsion target: ||T|| = {config['torsion_targets'][phase]}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if phase >= 3:\n",
        "            harmonic_extractors = {'enabled': True}\n",
        "\n",
        "        epoch_start = start_epoch if phase == start_phase else 0\n",
        "\n",
        "        phase_start_time = time.time()\n",
        "        phase_history = []  # NEW v1.1: Track history for this phase\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epoch_start, n_epochs_per_phase):\n",
        "            # NEW v1.1: Coefficient calibration at epoch 6000 (after Phase 4)\n",
        "            global_epoch = sum([config['n_epochs_per_phase'] for p in range(1, phase)]) + epoch\n",
        "            if global_epoch == config['rg_flow']['calibration_epoch'] and phase >= 4:\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"CALIBRATING RG FLOW COEFFICIENTS (Epoch {global_epoch})\")\n",
        "                print(f\"{'='*60}\")\n",
        "                \n",
        "                x0 = torch.zeros(7, device=device)\n",
        "                v0 = torch.tensor([0, -1e-3, 0, 0, 0, 0, 0], device=device, dtype=torch.float32)\n",
        "                \n",
        "                coeffs = calibrate_coefficients_global(\n",
        "                    phi_net, x0, v0, \n",
        "                    config['rg_flow']['lambda_max'],\n",
        "                    config['rg_flow']['target_delta_alpha']\n",
        "                )\n",
        "                \n",
        "                # Update functional and freeze\n",
        "                alpha_functional.A.data = torch.tensor(coeffs['A'], device=device)\n",
        "                alpha_functional.B.data = torch.tensor(coeffs['B'], device=device)\n",
        "                alpha_functional.A.requires_grad = False\n",
        "                alpha_functional.B.requires_grad = False\n",
        "                \n",
        "                print(f\"Coefficients calibrated and frozen for Phase 5\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "\n",
        "            phi_net.train()\n",
        "\n",
        "            coords = torch.rand(batch_size, 7, device=device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            losses = compute_complete_loss(\n",
        "                phi_net, coords, geometry, extd, config,\n",
        "                phase_config['weights'],\n",
        "                alpha_functional=alpha_functional if phase >= 4 else None,\n",
        "                geodesic_integrator=geodesic_integrator if phase >= 4 else None,\n",
        "                harmonic_extractors=harmonic_extractors if phase >= 3 else None,\n",
        "                phase=phase\n",
        "            )\n",
        "\n",
        "            losses['total'].backward()\n",
        "            torch.nn.utils.clip_grad_norm_(phi_net.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_entry = {\n",
        "                'phase': phase,\n",
        "                'epoch': epoch,\n",
        "                'global_epoch': global_epoch,\n",
        "                'total': losses['total'].item(),\n",
        "                'torsion': losses['torsion'].item(),\n",
        "                'actual_torsion': losses['actual_torsion'].item(),  # NEW v1.1\n",
        "                'det': losses['det'].item(),\n",
        "                'positivity': losses['positivity'].item(),\n",
        "                'neck_match': losses['neck_match'].item(),\n",
        "                'acyl': losses['acyl'].item(),\n",
        "                'harmonicity': losses['harmonicity'].item(),\n",
        "                'rg_flow': losses['rg_flow'].item(),  # NEW v1.1\n",
        "                'eig_floor': losses['eig_floor'].item()\n",
        "            }\n",
        "            loss_history.append(loss_entry)\n",
        "            phase_history.append(loss_entry)\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                elapsed = time.time() - phase_start_time\n",
        "                epochs_done = epoch + 1 - epoch_start\n",
        "                epochs_remaining = n_epochs_per_phase - (epoch + 1)\n",
        "                eta_seconds = (elapsed / epochs_done) * epochs_remaining if epochs_done > 0 else 0\n",
        "                eta_minutes = eta_seconds / 60\n",
        "\n",
        "                progress_pct = 100 * (epoch + 1) / n_epochs_per_phase\n",
        "                bar_length = 30\n",
        "                filled = int(bar_length * progress_pct / 100)\n",
        "                bar = '█' * filled + '░' * (bar_length - filled)\n",
        "\n",
        "                print(f\"[{bar}] {progress_pct:.1f}% | \"\n",
        "                      f\"Epoch {epoch+1}/{n_epochs_per_phase} | \"\n",
        "                      f\"Loss={losses['total'].item():.6f} | \"\n",
        "                      f\"||T||={losses['actual_torsion'].item():.4e} (target={config['torsion_targets'][phase]:.4e}) | \"\n",
        "                      f\"RG={losses['rg_flow'].item():.4e} | \"\n",
        "                      f\"ETA: {eta_minutes:.1f}m\")\n",
        "\n",
        "            # NEW v1.1: Per-phase early stopping\n",
        "            if check_phase_early_stop(losses, phase_config, phase_history, config):\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= phase_config['early_stop']['patience']:\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"Early stopping Phase {phase} at epoch {epoch+1}\")\n",
        "                    print(f\"All convergence criteria satisfied for {patience_counter} epochs\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "                    \n",
        "                    metadata = {\n",
        "                        'config': config,\n",
        "                        'phase': phase,\n",
        "                        'early_stopped': True,\n",
        "                        'final_loss': losses['total'].item(),\n",
        "                        'final_torsion': losses['actual_torsion'].item()\n",
        "                    }\n",
        "                    checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                    break\n",
        "            else:\n",
        "                patience_counter = 0\n",
        "\n",
        "            if checkpoint_mgr.should_save(epoch):\n",
        "                metadata = {\n",
        "                    'config': config,\n",
        "                    'current_phase': phase,\n",
        "                    'final_loss': losses['total'].item()\n",
        "                }\n",
        "                checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                print(f\"✓ Checkpoint saved\")\n",
        "\n",
        "        start_epoch = 0\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "print(\"Multi-phase training pipeline ready (v1.1 with systematic early stopping)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Execute Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting multi-phase training (v1.1)...\")\n",
        "print(f\"Extended neck: σ_neck={CONFIG['tcs']['neck_width']}\")\n",
        "print(f\"Torsion targeting: {CONFIG['torsion_targets']}\")\n",
        "print(f\"RG flow calibration: epoch {CONFIG['rg_flow']['calibration_epoch']}\")\n",
        "print(\"\")\n",
        "\n",
        "loss_history = train_multiphase(phi_net, geometry, extd, CONFIG, checkpoint_mgr, alpha_functional, geodesic_integrator)\n",
        "print(f\"\\nTraining complete. Final loss: {loss_history[-1]['total']:.6f}\")\n",
        "print(f\"Final torsion: ||T|| = {loss_history[-1]['actual_torsion']:.6e} (target: {CONFIG['target']['torsion_norm']:.6e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Post-Training: Harmonic Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Building discrete Laplacians (reduced grid)...\")\n",
        "n_grid_harm = CONFIG['n_grid_harmonics']\n",
        "print(f\"  Using {n_grid_harm}^7 = {n_grid_harm**7:,} points (reduced from {CONFIG['n_grid']**7:,})\")\n",
        "\n",
        "laplacian_2 = DiscreteLaplacian(n_grid_harm, dim=2)\n",
        "laplacian_3 = DiscreteLaplacian(n_grid_harm, dim=3)\n",
        "\n",
        "print(\"Extracting harmonic 2-forms...\")\n",
        "extractor_2 = LiveHarmonicExtractor(laplacian_2, CONFIG['target']['b2'])\n",
        "h2_modes, b2_eff = extractor_2.extract()\n",
        "print(f\"b₂_eff = {b2_eff} (target: {CONFIG['target']['b2']})\")\n",
        "\n",
        "print(\"Extracting harmonic 3-forms...\")\n",
        "extractor_3 = LiveHarmonicExtractor(laplacian_3, CONFIG['target']['b3'])\n",
        "h3_modes, b3_eff = extractor_3.extract()\n",
        "print(f\"b₃_eff = {b3_eff} (target: {CONFIG['target']['b3']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. Yukawa Tensor Construction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YukawaTensor:\n",
        "    def __init__(self, h2_modes: np.ndarray, h3_modes: np.ndarray, n_samples: int):\n",
        "        self.h2 = h2_modes\n",
        "        self.h3 = h3_modes\n",
        "        self.b2 = h2_modes.shape[1]\n",
        "        self.b3 = h3_modes.shape[1]\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "    def wedge_product(self, alpha: np.ndarray, beta: np.ndarray, gamma: np.ndarray) -> float:\n",
        "        indices = np.random.randint(0, len(alpha), self.n_samples)\n",
        "        integrand = alpha[indices] * beta[indices] * gamma[indices]\n",
        "        return np.mean(integrand)\n",
        "\n",
        "    def compute(self) -> np.ndarray:\n",
        "        Y = np.zeros((self.b2, self.b2, self.b3))\n",
        "        total = self.b2 * self.b2 * self.b3\n",
        "        count = 0\n",
        "\n",
        "        for alpha in range(self.b2):\n",
        "            for beta in range(self.b2):\n",
        "                for gamma in range(self.b3):\n",
        "                    Y[alpha, beta, gamma] = self.wedge_product(\n",
        "                        self.h2[:, alpha],\n",
        "                        self.h2[:, beta],\n",
        "                        self.h3[:, gamma]\n",
        "                    )\n",
        "\n",
        "                    count += 1\n",
        "                    if count % 5000 == 0:\n",
        "                        print(f\"Yukawa progress: {count}/{total} ({100*count/total:.1f}%)\")\n",
        "\n",
        "        return Y\n",
        "\n",
        "print(f\"Computing Yukawa tensor ({b2_eff}×{b2_eff}×{b3_eff})...\")\n",
        "yukawa = YukawaTensor(h2_modes, h3_modes, CONFIG['yukawa_samples'])\n",
        "Y_tensor = yukawa.compute()\n",
        "print(f\"Yukawa tensor shape: {Y_tensor.shape}\")\n",
        "print(f\"Yukawa tensor norm: {np.linalg.norm(Y_tensor):.6e}\")\n",
        "print(f\"NEW v1.1: Yukawa norm should be >>10⁻¹⁰ (v1.0f: ~10⁻¹⁰, expected v1.1: ~10⁻³ to 10⁻⁴)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. NEW v1.1: Comprehensive Validation (Torsion + RG Flow)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPREHENSIVE VALIDATION (v1.1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ==================================================================\n",
        "# 1. TORSION MAGNITUDE VALIDATION (CRITICAL)\n",
        "# ==================================================================\n",
        "print(\"\\n1. Torsion Magnitude Validation (v1.1 Critical Fix)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "phi_net.eval()\n",
        "with torch.no_grad():\n",
        "    n_samples = 10000\n",
        "    test_coords = torch.rand(n_samples, 7, device=device)\n",
        "    \n",
        "    phi_vals = phi_net(test_coords)\n",
        "    g_vals, g_inv = compute_g2_metric(phi_vals, phase=5)\n",
        "    g_corrected = geometry.acyl_metric_correction(test_coords, g_vals)\n",
        "    g_normalized = normalize_metric(g_corrected, CONFIG['target']['det_g'])\n",
        "    \n",
        "    # Compute Hodge dual for complete torsion\n",
        "    psi_vals = compute_hodge_dual(phi_vals, g_normalized, g_inv)\n",
        "    \n",
        "    jacobian = extd.compute_jacobian(phi_net, test_coords)\n",
        "    dphi = extd.d_phi(jacobian)\n",
        "    dpsi_norm = extd.d_psi_norm(psi_vals, phi_net, test_coords)\n",
        "    \n",
        "    # Compute COMPLETE torsion per-point (dphi + dpsi)\n",
        "    dphi_per_point = torch.sqrt((dphi ** 2).sum(dim=(-4, -3, -2, -1)))\n",
        "    torsion_per_point = torch.sqrt(dphi_per_point**2 + dpsi_norm**2)\n",
        "    \n",
        "    torsion_mean = torsion_per_point.mean().item()\n",
        "    torsion_max = torsion_per_point.max().item()\n",
        "    torsion_std = torsion_per_point.std().item()\n",
        "    \n",
        "    det_g = torch.linalg.det(g_normalized)\n",
        "\n",
        "target_torsion = CONFIG['target']['torsion_norm']\n",
        "torsion_error = abs(torsion_mean - target_torsion) / target_torsion * 100\n",
        "\n",
        "print(f\"  Target torsion: ||T|| = {target_torsion:.6e}\")\n",
        "print(f\"  Actual torsion: ||T|| = {torsion_mean:.6e}\")\n",
        "print(f\"  Error: {torsion_error:.2f}%\")\n",
        "print(f\"  Range: [{torsion_per_point.min().item():.6e}, {torsion_max:.6e}]\")\n",
        "print(f\"  Std: {torsion_std:.6e}\")\n",
        "\n",
        "if torsion_error < 10:\n",
        "    print(f\"  ✓ Torsion within 10% of target (SUCCESS)\")\n",
        "elif torsion_error < 30:\n",
        "    print(f\"  ⚠ Torsion within 30% of target (ACCEPTABLE)\")\n",
        "else:\n",
        "    print(f\"  ✗ Torsion error too large (NEEDS IMPROVEMENT)\")\n",
        "\n",
        "print(f\"\\n  v1.0f comparison: ||T|| = 8.35×10⁻⁴ (94.9% error)\")\n",
        "print(f\"  v1.1 improvement: {(torsion_mean / 8.35e-4):.1f}× closer to target\")\n",
        "\n",
        "# ==================================================================\n",
        "# 2. RG FLOW VALIDATION (NEW)\n",
        "# ==================================================================\n",
        "print(\"\\n2. RG Flow Validation (NEW v1.1)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "print(\"  Integrating geodesic from M_Z to M_Planck...\")\n",
        "x0 = torch.zeros(7, device=device)\n",
        "v0 = torch.tensor([0, -1e-3, 0, 0, 0, 0, 0], device=device, dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_traj, v_traj = geodesic_integrator.integrate_rk4(\n",
        "        x0, v0,\n",
        "        CONFIG['rg_flow']['lambda_max'],\n",
        "        CONFIG['rg_flow']['n_integration_steps']\n",
        "    )\n",
        "    \n",
        "    # Compute α⁻¹ at endpoints\n",
        "    phi_start = phi_net(x_traj[0:1])\n",
        "    g_start, _ = compute_g2_metric(phi_start, phase=5)\n",
        "    g_start = geometry.acyl_metric_correction(x_traj[0:1], g_start)\n",
        "    g_start = normalize_metric(g_start, CONFIG['target']['det_g'])\n",
        "    \n",
        "    jacobian_start = extd.compute_jacobian(phi_net, x_traj[0:1])\n",
        "    dphi_start = extd.d_phi(jacobian_start)\n",
        "    \n",
        "    alpha_start = alpha_functional(g_start, dphi_start)\n",
        "    \n",
        "    phi_end = phi_net(x_traj[-1:])\n",
        "    g_end, _ = compute_g2_metric(phi_end, phase=5)\n",
        "    g_end = geometry.acyl_metric_correction(x_traj[-1:], g_end)\n",
        "    g_end = normalize_metric(g_end, CONFIG['target']['det_g'])\n",
        "    \n",
        "    jacobian_end = extd.compute_jacobian(phi_net, x_traj[-1:])\n",
        "    dphi_end = extd.d_phi(jacobian_end)\n",
        "    \n",
        "    alpha_end = alpha_functional(g_end, dphi_end)\n",
        "    \n",
        "    delta_alpha = (alpha_end.mean() - alpha_start.mean()).item()\n",
        "\n",
        "target_delta = CONFIG['rg_flow']['target_delta_alpha']\n",
        "rg_error = abs(delta_alpha - target_delta) / abs(target_delta) * 100\n",
        "\n",
        "print(f\"  α⁻¹(M_Z) = {alpha_start.item():.3f}\")\n",
        "print(f\"  α⁻¹(M_Planck) = {alpha_end.item():.3f}\")\n",
        "print(f\"  Δα⁻¹ = {delta_alpha:.4f}\")\n",
        "print(f\"  Target: Δα⁻¹ = {target_delta:.4f}\")\n",
        "print(f\"  Error: {rg_error:.2f}%\")\n",
        "\n",
        "if rg_error < 5:\n",
        "    print(f\"  ✓ RG flow within 5% of target (SUCCESS)\")\n",
        "elif rg_error < 10:\n",
        "    print(f\"  ⚠ RG flow within 10% of target (ACCEPTABLE)\")\n",
        "else:\n",
        "    print(f\"  ✗ RG flow error too large (NEEDS IMPROVEMENT)\")\n",
        "\n",
        "# ==================================================================\n",
        "# 3. GEOMETRIC QUALITY (PRESERVED FROM v1.0f)\n",
        "# ==================================================================\n",
        "print(\"\\n3. Geometric Quality (Should Be Preserved)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "g_sym = (g_normalized + g_normalized.transpose(-2, -1)) / 2.0\n",
        "eigvals = torch.linalg.eigvalsh(g_sym)\n",
        "\n",
        "det_mean = det_g.mean().item()\n",
        "det_std = det_g.std().item()\n",
        "det_error = abs(det_mean - CONFIG['target']['det_g']) / CONFIG['target']['det_g'] * 100\n",
        "\n",
        "eig_min = eigvals.min().item()\n",
        "positive_definite = (eigvals > 0).all().item()\n",
        "\n",
        "print(f\"  det(g) = {det_mean:.7f} ± {det_std:.2e}\")\n",
        "print(f\"  Target: det(g) = {CONFIG['target']['det_g']}\")\n",
        "print(f\"  Error: {det_error:.4f}%\")\n",
        "print(f\"  Eigenvalues: min={eig_min:.6f}, max={eigvals.max().item():.6f}\")\n",
        "print(f\"  Positive definite: {positive_definite}\")\n",
        "\n",
        "if det_error < 0.01 and positive_definite:\n",
        "    print(f\"  ✓ Geometric quality preserved (SUCCESS)\")\n",
        "else:\n",
        "    print(f\"  ⚠ Geometric quality degraded\")\n",
        "\n",
        "# ==================================================================\n",
        "# 4. PHENOMENOLOGICAL VIABILITY\n",
        "# ==================================================================\n",
        "print(\"\\n4. Phenomenological Viability\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "yukawa_norm = np.linalg.norm(Y_tensor)\n",
        "yukawa_max = np.abs(Y_tensor).max()\n",
        "yukawa_nonzero_frac = (np.abs(Y_tensor) > 1e-8).mean()\n",
        "\n",
        "print(f\"  Yukawa norm: {yukawa_norm:.6e}\")\n",
        "print(f\"  Max |Y|: {yukawa_max:.6e}\")\n",
        "print(f\"  Non-zero fraction: {yukawa_nonzero_frac:.3f}\")\n",
        "\n",
        "if yukawa_norm > 1e-5:\n",
        "    print(f\"  ✓ Yukawa couplings non-negligible (SUCCESS)\")\n",
        "elif yukawa_norm > 1e-8:\n",
        "    print(f\"  ⚠ Yukawa couplings weak but non-zero (MARGINAL)\")\n",
        "else:\n",
        "    print(f\"  ✗ Yukawa couplings negligible (FAILURE)\")\n",
        "\n",
        "print(f\"\\n  v1.0f comparison: Yukawa norm ~10⁻¹⁰\")\n",
        "if yukawa_norm > 1e-10:\n",
        "    print(f\"  v1.1 improvement: {yukawa_norm / 1e-10:.1f}× larger\")\n",
        "\n",
        "# ==================================================================\n",
        "# 5. SUMMARY\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION SUMMARY (v1.1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_tests_passed = (\n",
        "    torsion_error < 10 and\n",
        "    rg_error < 10 and\n",
        "    det_error < 0.01 and\n",
        "    positive_definite and\n",
        "    yukawa_norm > 1e-5\n",
        ")\n",
        "\n",
        "print(f\"Torsion target reached: {'✓' if torsion_error < 10 else '✗'}\")\n",
        "print(f\"RG flow correct: {'✓' if rg_error < 10 else '✗'}\")\n",
        "print(f\"Geometric quality preserved: {'✓' if (det_error < 0.01 and positive_definite) else '✗'}\")\n",
        "print(f\"Yukawa viable: {'✓' if yukawa_norm > 1e-5 else '✗'}\")\n",
        "print(f\"\\nOverall: {'SUCCESS' if all_tests_passed else 'PARTIAL SUCCESS - Iteration may be needed'}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = Path('outputs_v1_1')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save harmonics and Yukawa\n",
        "np.save(output_dir / 'harmonic_2forms.npy', h2_modes)\n",
        "np.save(output_dir / 'harmonic_3forms.npy', h3_modes)\n",
        "np.save(output_dir / 'yukawa_tensor.npy', Y_tensor)\n",
        "\n",
        "# Save phi and metric samples\n",
        "phi_net.eval()\n",
        "with torch.no_grad():\n",
        "    test_coords = torch.rand(5000, 7, device=device)\n",
        "    phi_samples = phi_net(test_coords).cpu().numpy()\n",
        "    np.save(output_dir / 'phi_samples.npy', phi_samples)\n",
        "\n",
        "    g_samples, _ = compute_g2_metric(phi_net(test_coords))\n",
        "    g_samples = geometry.acyl_metric_correction(test_coords, g_samples)\n",
        "    np.save(output_dir / 'metric_samples.npy', g_samples.cpu().numpy())\n",
        "\n",
        "# Save loss history\n",
        "loss_df = pd.DataFrame(loss_history)\n",
        "loss_df.to_csv(output_dir / 'training_history.csv', index=False)\n",
        "\n",
        "# Save metadata with v1.1 specific info\n",
        "metadata = {\n",
        "    'version': '1.1',\n",
        "    'config': CONFIG,\n",
        "    'training_grid': f\"{CONFIG['n_grid']}^7\",\n",
        "    'harmonics_grid': f\"{CONFIG['n_grid_harmonics']}^7\",\n",
        "    'b2_effective': b2_eff,\n",
        "    'b3_effective': b3_eff,\n",
        "    'b2_target': CONFIG['target']['b2'],\n",
        "    'b3_target': CONFIG['target']['b3'],\n",
        "    'yukawa_shape': list(Y_tensor.shape),\n",
        "    'yukawa_norm': float(yukawa_norm),\n",
        "    'final_loss': loss_history[-1]['total'] if loss_history else None,\n",
        "    'total_epochs': len(loss_history),\n",
        "    'torsion_validation': {\n",
        "        'target': target_torsion,\n",
        "        'actual': torsion_mean,\n",
        "        'error_percent': torsion_error,\n",
        "        'passed': torsion_error < 10\n",
        "    },\n",
        "    'rg_flow_validation': {\n",
        "        'target_delta_alpha': target_delta,\n",
        "        'actual_delta_alpha': delta_alpha,\n",
        "        'error_percent': rg_error,\n",
        "        'passed': rg_error < 10\n",
        "    },\n",
        "    'geometric_validation': {\n",
        "        'det_g_mean': det_mean,\n",
        "        'det_g_error_percent': det_error,\n",
        "        'positive_definite': positive_definite,\n",
        "        'passed': det_error < 0.01 and positive_definite\n",
        "    },\n",
        "    'phenomenological_validation': {\n",
        "        'yukawa_norm': yukawa_norm,\n",
        "        'passed': yukawa_norm > 1e-5\n",
        "    },\n",
        "    'note': 'v1.1: Torsion targeting + RG flow integration + Extended neck + Per-phase early stopping'\n",
        "}\n",
        "\n",
        "with open(output_dir / 'metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {output_dir}\")\n",
        "print(f\"\\nKey outputs:\")\n",
        "print(f\"  - training_history.csv: Complete loss history with torsion tracking\")\n",
        "print(f\"  - harmonic_2forms.npy, harmonic_3forms.npy: Cohomology bases\")\n",
        "print(f\"  - yukawa_tensor.npy: ({b2_eff}×{b2_eff}×{b3_eff}) coupling tensor\")\n",
        "print(f\"  - metadata.json: Validation results and configuration\")\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"GIFT v1.1 PIPELINE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Torsion: {'✓' if torsion_error < 10 else '✗'} ({torsion_error:.1f}% error)\")\n",
        "print(f\"RG flow: {'✓' if rg_error < 10 else '✗'} ({rg_error:.1f}% error)\")\n",
        "print(f\"Geometry: {'✓' if (det_error < 0.01 and positive_definite) else '✗'}\")\n",
        "print(f\"Yukawa: {'✓' if yukawa_norm > 1e-5 else '✗'} (norm={yukawa_norm:.2e})\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
