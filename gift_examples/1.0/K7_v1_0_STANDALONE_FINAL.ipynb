{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6df3a6f"
      },
      "source": [
        "# K₇ Metric Reconstruction v1.0 - Standalone\n",
        "\n",
        "**100% self-contained** - no external files needed.\n",
        "\n",
        "All outputs to `/content/K7_v1_0_training/` (Colab local storage).\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "1. Runtime → Change runtime type → GPU\n",
        "2. Runtime → Run all\n",
        "3. Download results before session ends\n",
        "\n",
        "**Framework:** GIFT v2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f1a651a"
      },
      "source": [
        "# Install dependencies\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print('Installing packages...')\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q tensorly\n",
        "!pip install -q matplotlib seaborn\n",
        "print('Installation complete')\n",
        "\n",
        "# Setup directories (local storage only)\n",
        "WORK_DIR = Path('/content/K7_v1_0_training')\n",
        "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CHECKPOINT_DIR = WORK_DIR / 'checkpoints'\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RESULTS_DIR = WORK_DIR / 'results'\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f'Working directory: {WORK_DIR}')\n",
        "print('NOTE: All data in /content/ - download before session ends!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99d12da1"
      },
      "source": [
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from itertools import permutations\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
        "else:\n",
        "    print('WARNING: No GPU - training will be very slow!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6f3ab63"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26bd92f5"
      },
      "source": [
        "CONFIG = {\n",
        "    'version': 'v1.0_standalone',\n",
        "    'seed': 42,\n",
        "    'gift_parameters': {\n",
        "        'tau': 3.8967452300785634,\n",
        "        'xi': 0.9817477042468103,\n",
        "        'epsilon0': 0.125,\n",
        "        'b2': 21,\n",
        "        'b3': 77,\n",
        "    },\n",
        "    'architecture': {\n",
        "        'phi_network': {'hidden_dims': [384, 384, 256], 'n_fourier': 32},\n",
        "        'harmonic_h2_network': {'hidden_dim': 128, 'n_fourier': 24, 'n_forms': 21},\n",
        "        'harmonic_h3_network': {'hidden_dim': 128, 'n_fourier': 24, 'n_forms': 77}\n",
        "    },\n",
        "    'training': {\n",
        "        'total_epochs': 15000,\n",
        "        'batch_size': 2048,\n",
        "        'grad_accumulation': 4,\n",
        "        'lr': 1e-4,\n",
        "        'weight_decay': 1e-4,\n",
        "        'grad_clip': 1.0,\n",
        "        'warmup_epochs': 500,\n",
        "    },\n",
        "    'checkpointing': {\n",
        "        'interval': 500,\n",
        "        'keep_best': 5,\n",
        "        'auto_resume': True\n",
        "    },\n",
        "}\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(CONFIG['seed'])\n",
        "torch.manual_seed(CONFIG['seed'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(CONFIG['seed'])\n",
        "\n",
        "# Save config\n",
        "with open(WORK_DIR / 'config.json', 'w') as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "print('Configuration initialized')\n",
        "print(f'Total epochs: {CONFIG[\"training\"][\"total_epochs\"]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a60a66f8"
      },
      "source": [
        "## Complete Implementation\n",
        "\n",
        "All modules inline (~1450 lines):\n",
        "- Checkpoint management\n",
        "- Loss functions\n",
        "- Training loop\n",
        "- Validation\n",
        "- Yukawa computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "807c9478"
      },
      "source": [
        "# ============================================================\n",
        "# COMPLETE K7 v1.0 IMPLEMENTATION - ALL MODULES INLINE\n",
        "# ============================================================\n",
        "\n",
        "# ============================================================\n",
        "# NEURAL NETWORK ARCHITECTURES\n",
        "# ============================================================\n",
        "\n",
        "class FourierFeatures(nn.Module):\n",
        "    def __init__(self, input_dim, n_frequencies, scale=1.0):\n",
        "        super().__init__()\n",
        "        B = torch.randn(input_dim, n_frequencies) * scale\n",
        "        self.register_buffer('B', B)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_proj = 2 * np.pi * x @ self.B\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "\n",
        "class ModularPhiNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dims, n_fourier):\n",
        "        super().__init__()\n",
        "        self.fourier = FourierFeatures(7, n_fourier, scale=1.0)\n",
        "\n",
        "        layers = []\n",
        "        in_dim = self.fourier.B.shape[0] * self.fourier.B.shape[1] * 2\n",
        "        for h_dim in hidden_dims:\n",
        "            layers.extend([nn.Linear(in_dim, h_dim), nn.SiLU()])\n",
        "            in_dim = h_dim\n",
        "\n",
        "        layers.append(nn.Linear(in_dim, 35))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.fourier(x)\n",
        "        return self.network(features)\n",
        "\n",
        "    def get_phi_tensor(self, x):\n",
        "        phi_flat = self.forward(x)\n",
        "        batch_size = x.shape[0]\n",
        "        phi = torch.zeros(batch_size, 7, 7, 7, device=x.device)\n",
        "\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    val = phi_flat[:, idx]\n",
        "                    phi[:, i, j, k] = val\n",
        "                    phi[:, i, k, j] = -val\n",
        "                    phi[:, j, i, k] = -val\n",
        "                    phi[:, j, k, i] = val\n",
        "                    phi[:, k, i, j] = val\n",
        "                    phi[:, k, j, i] = -val\n",
        "                    idx += 1\n",
        "\n",
        "        return phi\n",
        "\n",
        "\n",
        "class HarmonicFormsNetwork(nn.Module):\n",
        "    def __init__(self, p, n_forms, hidden_dim, n_fourier):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.n_forms = n_forms\n",
        "        self.n_components = 21 if p == 2 else 35\n",
        "\n",
        "        self.networks = nn.ModuleList()\n",
        "        for i in range(n_forms):\n",
        "            hidden_var = hidden_dim + (i % 5) * 8\n",
        "            fourier = FourierFeatures(7, n_fourier, scale=1.0)\n",
        "            fourier_dim = 7 * n_fourier * 2\n",
        "            net = nn.Sequential(\n",
        "                nn.Linear(fourier_dim, hidden_var),\n",
        "                nn.SiLU(),\n",
        "                nn.Linear(hidden_var, hidden_var),\n",
        "                nn.SiLU(),\n",
        "                nn.Linear(hidden_var, self.n_components),\n",
        "            )\n",
        "            self.networks.append(nn.Sequential(fourier, net))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = torch.zeros(batch_size, self.n_forms, self.n_components, device=x.device)\n",
        "\n",
        "        for i, network in enumerate(self.networks):\n",
        "            outputs[:, i, :] = network(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class K7Topology:\n",
        "    def __init__(self, gift_params):\n",
        "        self.params = gift_params\n",
        "        self.epsilon = gift_params['epsilon0']\n",
        "\n",
        "    def sample_coordinates(self, n_samples, grid_n=10):\n",
        "        coords_1d = torch.linspace(0, 2*np.pi, grid_n)\n",
        "        grid_7d = torch.stack(torch.meshgrid(*[coords_1d]*7, indexing='ij'), dim=-1)\n",
        "        grid_flat = grid_7d.reshape(-1, 7)\n",
        "\n",
        "        n_grid = min(n_samples // 2, grid_flat.shape[0])\n",
        "        idx_grid = torch.randperm(grid_flat.shape[0])[:n_grid]\n",
        "        samples_grid = grid_flat[idx_grid]\n",
        "\n",
        "        n_random = n_samples - n_grid\n",
        "        samples_random = torch.rand(n_random, 7) * 2 * np.pi\n",
        "\n",
        "        return torch.cat([samples_grid, samples_random], dim=0)\n",
        "\n",
        "    def get_region_weights(self, x):\n",
        "        t = x[:, 0]\n",
        "        w_m1 = torch.sigmoid((np.pi - t) / 0.3)\n",
        "        w_m2 = torch.sigmoid((t - np.pi) / 0.3)\n",
        "        w_neck = 1.0 - w_m1 - w_m2\n",
        "        return {'m1': w_m1, 'neck': w_neck, 'm2': w_m2}\n",
        "\n",
        "    def define_associative_cycles(self, n_cycles=6):\n",
        "        cycles = []\n",
        "        for region, t_vals in [('M1', [np.pi/4, np.pi/3]),\n",
        "                                ('neck', [np.pi, 5*np.pi/4]),\n",
        "                                ('M2', [3*np.pi/2, 7*np.pi/4])]:\n",
        "            for t in t_vals:\n",
        "                cycles.append({\n",
        "                    'region': region,\n",
        "                    't_fixed': t,\n",
        "                    'type': 'T3',\n",
        "                    'indices': [1, 2, 3],\n",
        "                })\n",
        "        return cycles[:n_cycles]\n",
        "\n",
        "    def define_coassociative_cycles(self, n_cycles=6):\n",
        "        cycles = []\n",
        "        for region, t_vals in [('M1', [np.pi/4]),\n",
        "                                ('neck', [np.pi, 5*np.pi/4]),\n",
        "                                ('M2', [3*np.pi/2, 7*np.pi/4])]:\n",
        "            for t in t_vals:\n",
        "                cycles.append({\n",
        "                    'region': region,\n",
        "                    't_fixed': t,\n",
        "                    'type': 'T4',\n",
        "                    'indices': [0, 4, 5, 6],\n",
        "                })\n",
        "        return cycles[:n_cycles]\n",
        "\n",
        "    def sample_on_cycle(self, cycle, n_samples=512):\n",
        "        samples = torch.rand(n_samples, 7) * 2 * np.pi\n",
        "        samples[:, 0] = cycle['t_fixed']\n",
        "        return samples\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CHECKPOINT MANAGEMENT\n",
        "# ============================================================\n",
        "\n",
        "class CheckpointManager:\n",
        "    def __init__(self, save_dir, keep_best=5):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(exist_ok=True)\n",
        "        self.keep_best = keep_best\n",
        "        self.checkpoints = []\n",
        "    \n",
        "    def save(self, epoch, models, optimizer, scheduler, metrics):\n",
        "        path = self.save_dir / f'checkpoint_epoch_{epoch}.pt'\n",
        "        temp = self.save_dir / f'checkpoint_epoch_{epoch}.pt.tmp'\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'models': {n: m.state_dict() for n, m in models.items()},\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict() if scheduler else None,\n",
        "            'metrics': metrics,\n",
        "            'timestamp': time.time()\n",
        "        }, temp)\n",
        "        temp.rename(path)\n",
        "        \n",
        "        torsion = metrics.get('torsion_closure', 1.0) + metrics.get('torsion_coclosure', 1.0)\n",
        "        self.checkpoints.append((epoch, torsion, path))\n",
        "        self.checkpoints.sort(key=lambda x: x[1])\n",
        "        \n",
        "        if len(self.checkpoints) > self.keep_best:\n",
        "            _, _, old = self.checkpoints.pop()\n",
        "            if old.exists() and old != path:\n",
        "                old.unlink()\n",
        "        return path\n",
        "    \n",
        "    def load_latest(self):\n",
        "        ckpts = sorted(self.save_dir.glob('checkpoint_*.pt'), reverse=True)\n",
        "        for ckpt in ckpts:\n",
        "            try:\n",
        "                print(f'Loading: {ckpt.name}')\n",
        "                return torch.load(ckpt, map_location=DEVICE)\n",
        "            except Exception as e:\n",
        "                print(f'Failed: {e}')\n",
        "                continue\n",
        "        return None\n",
        "\n",
        "checkpoint_manager = CheckpointManager(CHECKPOINT_DIR, CONFIG['checkpointing']['keep_best'])\n",
        "print('Checkpoint manager initialized')\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# LOSSES MODULE\n",
        "# ============================================================\n",
        "\n",
        "def torsion_closure_loss(dphi: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Torsion closure constraint: dφ = 0.\n",
        "\n",
        "    Args:\n",
        "        dphi: [batch, 7, 7, 7, 7] exterior derivative of 3-form\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    return torch.mean(dphi ** 2)\n",
        "\n",
        "\n",
        "def torsion_coclosure_loss(dstar_phi: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Torsion coclosure constraint: d*φ = 0.\n",
        "\n",
        "    Args:\n",
        "        dstar_phi: [batch, 7, 7] co-derivative of 3-form\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    return torch.mean(dstar_phi ** 2)\n",
        "\n",
        "\n",
        "def volume_loss(metric: torch.Tensor, target_det: float = 1.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Volume constraint: det(g) ≈ target_det.\n",
        "\n",
        "    Args:\n",
        "        metric: [batch, 7, 7] metric tensor\n",
        "        target_det: Target determinant value\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    det = torch.det(metric)\n",
        "    return torch.mean((det - target_det) ** 2)\n",
        "\n",
        "\n",
        "def gram_matrix_loss(harmonic_forms: torch.Tensor, target_rank: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "    \"\"\"\n",
        "    Gram matrix orthonormalization loss for harmonic forms.\n",
        "\n",
        "    Enforces:\n",
        "    1. Orthonormality: G_ij ≈ δ_ij\n",
        "    2. Full rank: rank(G) = target_rank\n",
        "    3. det(G) ≈ 1\n",
        "\n",
        "    Args:\n",
        "        harmonic_forms: [batch, n_forms, n_components] harmonic basis\n",
        "        target_rank: Expected rank (21 for b₂, 77 for b₃)\n",
        "\n",
        "    Returns:\n",
        "        loss: Total Gram loss\n",
        "        det_gram: Determinant of Gram matrix\n",
        "        rank: Numerical rank\n",
        "    \"\"\"\n",
        "    batch_size, n_forms, n_components = harmonic_forms.shape\n",
        "\n",
        "    gram = torch.zeros(n_forms, n_forms, device=harmonic_forms.device)\n",
        "    for i in range(n_forms):\n",
        "        for j in range(n_forms):\n",
        "            inner_product = torch.mean(\n",
        "                torch.sum(harmonic_forms[:, i, :] * harmonic_forms[:, j, :], dim=-1)\n",
        "            )\n",
        "            gram[i, j] = inner_product\n",
        "\n",
        "    identity = torch.eye(n_forms, device=gram.device)\n",
        "\n",
        "    loss_orthonormality = torch.mean((gram - identity) ** 2)\n",
        "\n",
        "    det_gram = torch.det(gram + 1e-6 * identity)\n",
        "    loss_determinant = (det_gram - 1.0) ** 2\n",
        "\n",
        "    eigenvalues = torch.linalg.eigvalsh(gram)\n",
        "    rank = (eigenvalues > 1e-4).sum().item()\n",
        "\n",
        "    loss = loss_orthonormality + 0.1 * loss_determinant\n",
        "\n",
        "    return loss, det_gram, rank\n",
        "\n",
        "\n",
        "def boundary_smoothness_loss(phi: torch.Tensor, region_weights: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Boundary smoothness between M₁, Neck, and M₂ regions.\n",
        "\n",
        "    Penalizes discontinuities at region transitions.\n",
        "\n",
        "    Args:\n",
        "        phi: [batch, 7, 7, 7] 3-form\n",
        "        region_weights: Dictionary of soft region assignments\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    w_m1 = region_weights['m1'].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "    w_neck = region_weights['neck'].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "    w_m2 = region_weights['m2'].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "    transition_m1_neck = torch.mean((w_m1 * w_neck).unsqueeze(-1) * phi ** 2)\n",
        "    transition_neck_m2 = torch.mean((w_neck * w_m2).unsqueeze(-1) * phi ** 2)\n",
        "\n",
        "    return transition_m1_neck + transition_neck_m2\n",
        "\n",
        "\n",
        "def calibration_associative_loss(\n",
        "    phi: torch.Tensor,\n",
        "    cycles: List[Dict],\n",
        "    topology,\n",
        "    n_samples: int = 512\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calibration constraint for associative 3-cycles: φ|_Σ = vol_Σ.\n",
        "\n",
        "    Args:\n",
        "        phi: [batch, 7, 7, 7] 3-form\n",
        "        cycles: List of associative cycle definitions\n",
        "        topology: K7Topology instance\n",
        "        n_samples: Samples per cycle for integration\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    n_cycles = len(cycles)\n",
        "\n",
        "    for cycle in cycles:\n",
        "        samples = topology.sample_on_cycle(cycle, n_samples)\n",
        "        samples = samples.to(phi.device)\n",
        "\n",
        "        phi_on_cycle = torch.zeros(samples.shape[0], device=phi.device)\n",
        "\n",
        "        indices = cycle['indices']\n",
        "        if len(indices) == 3:\n",
        "            i, j, k = indices\n",
        "            phi_on_cycle = torch.abs(phi[:, i, j, k].mean())\n",
        "\n",
        "        volume_sigma = 1.0\n",
        "\n",
        "        loss_cycle = (phi_on_cycle - volume_sigma) ** 2\n",
        "        total_loss += loss_cycle\n",
        "\n",
        "    return total_loss / max(n_cycles, 1)\n",
        "\n",
        "\n",
        "def calibration_coassociative_loss(\n",
        "    star_phi: torch.Tensor,\n",
        "    cycles: List[Dict],\n",
        "    topology,\n",
        "    n_samples: int = 512\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calibration constraint for coassociative 4-cycles: *φ|_Ω = vol_Ω.\n",
        "\n",
        "    Args:\n",
        "        star_phi: [batch, 7, 7, 7, 7] Hodge dual 4-form\n",
        "        cycles: List of coassociative cycle definitions\n",
        "        topology: K7Topology instance\n",
        "        n_samples: Samples per cycle\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    n_cycles = len(cycles)\n",
        "\n",
        "    for cycle in cycles:\n",
        "        samples = topology.sample_on_cycle(cycle, n_samples)\n",
        "        samples = samples.to(star_phi.device)\n",
        "\n",
        "        star_phi_on_cycle = torch.zeros(samples.shape[0], device=star_phi.device)\n",
        "\n",
        "        indices = cycle['indices']\n",
        "        if len(indices) == 4:\n",
        "            i, j, k, l = indices\n",
        "            star_phi_on_cycle = torch.abs(star_phi[:, i, j, k, l].mean())\n",
        "\n",
        "        volume_omega = 1.0\n",
        "\n",
        "        loss_cycle = (star_phi_on_cycle - volume_omega) ** 2\n",
        "        total_loss += loss_cycle\n",
        "\n",
        "    return total_loss / max(n_cycles, 1)\n",
        "\n",
        "\n",
        "class AdaptiveLossScheduler:\n",
        "    \"\"\"\n",
        "    Adaptive loss weight scheduler based on training dynamics.\n",
        "\n",
        "    Monitors torsion component stagnation and dynamically adjusts weights.\n",
        "    \"\"\"\n",
        "    def __init__(self, check_interval: int = 100, plateau_threshold: float = 1e-4):\n",
        "        self.check_interval = check_interval\n",
        "        self.plateau_threshold = plateau_threshold\n",
        "        self.history = {'torsion_closure': [], 'torsion_coclosure': []}\n",
        "        self.weights = {'torsion_closure': 1.0, 'torsion_coclosure': 1.0}\n",
        "\n",
        "    def update(self, epoch: int, losses: Dict[str, float]):\n",
        "        \"\"\"\n",
        "        Update loss history and adjust weights if plateau detected.\n",
        "        \"\"\"\n",
        "        for key in ['torsion_closure', 'torsion_coclosure']:\n",
        "            if key in losses:\n",
        "                self.history[key].append(losses[key])\n",
        "\n",
        "        if epoch % self.check_interval == 0 and epoch > 500:\n",
        "            for key in ['torsion_closure', 'torsion_coclosure']:\n",
        "                if len(self.history[key]) >= 100:\n",
        "                    recent = self.history[key][-100:]\n",
        "                    variance = torch.tensor(recent).var().item()\n",
        "\n",
        "                    if variance < self.plateau_threshold:\n",
        "                        self.weights[key] *= 1.5\n",
        "                        print(f\"Epoch {epoch}: Boosting {key} weight to {self.weights[key]:.3f}\")\n",
        "\n",
        "    def get_weights(self) -> Dict[str, float]:\n",
        "        return self.weights\n",
        "\n",
        "\n",
        "class CompositeLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Composite loss function combining all geometric constraints.\n",
        "    \"\"\"\n",
        "    def __init__(self, topology, assoc_cycles, coassoc_cycles):\n",
        "        super().__init__()\n",
        "        self.topology = topology\n",
        "        self.assoc_cycles = assoc_cycles\n",
        "        self.coassoc_cycles = coassoc_cycles\n",
        "        self.adaptive_scheduler = AdaptiveLossScheduler()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        phi: torch.Tensor,\n",
        "        dphi: torch.Tensor,\n",
        "        dstar_phi: torch.Tensor,\n",
        "        star_phi: torch.Tensor,\n",
        "        metric: torch.Tensor,\n",
        "        harmonic_h2: torch.Tensor,\n",
        "        harmonic_h3: torch.Tensor,\n",
        "        region_weights: Dict[str, torch.Tensor],\n",
        "        loss_weights: Dict[str, float],\n",
        "        epoch: int = 0\n",
        "    ) -> Tuple[torch.Tensor, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Compute total loss and component breakdown.\n",
        "\n",
        "        Returns:\n",
        "            total_loss: Weighted sum of all components\n",
        "            components: Dictionary of individual loss values\n",
        "        \"\"\"\n",
        "        components = {}\n",
        "\n",
        "        components['torsion_closure'] = torsion_closure_loss(dphi)\n",
        "        components['torsion_coclosure'] = torsion_coclosure_loss(dstar_phi)\n",
        "        components['volume'] = volume_loss(metric)\n",
        "\n",
        "        gram_h2_loss, det_h2, rank_h2 = gram_matrix_loss(\n",
        "            harmonic_h2, target_rank=21\n",
        "        )\n",
        "        components['gram_h2'] = gram_h2_loss\n",
        "        components['det_gram_h2'] = det_h2.item()\n",
        "        components['rank_h2'] = rank_h2\n",
        "\n",
        "        gram_h3_loss, det_h3, rank_h3 = gram_matrix_loss(\n",
        "            harmonic_h3, target_rank=77\n",
        "        )\n",
        "        components['gram_h3'] = gram_h3_loss\n",
        "        components['det_gram_h3'] = det_h3.item()\n",
        "        components['rank_h3'] = rank_h3\n",
        "\n",
        "        components['boundary'] = boundary_smoothness_loss(phi, region_weights)\n",
        "\n",
        "        if loss_weights.get('calibration', 0.0) > 0:\n",
        "            components['calibration_assoc'] = calibration_associative_loss(\n",
        "                phi, self.assoc_cycles, self.topology\n",
        "            )\n",
        "            components['calibration_coassoc'] = calibration_coassociative_loss(\n",
        "                star_phi, self.coassoc_cycles, self.topology\n",
        "            )\n",
        "            components['calibration'] = (\n",
        "                components['calibration_assoc'] + components['calibration_coassoc']\n",
        "            ) / 2.0\n",
        "        else:\n",
        "            components['calibration'] = torch.tensor(0.0, device=phi.device)\n",
        "\n",
        "        self.adaptive_scheduler.update(epoch, {\n",
        "            'torsion_closure': components['torsion_closure'].item(),\n",
        "            'torsion_coclosure': components['torsion_coclosure'].item()\n",
        "        })\n",
        "        adaptive_weights = self.adaptive_scheduler.get_weights()\n",
        "\n",
        "        total_loss = (\n",
        "            loss_weights.get('torsion_closure', 1.0) * adaptive_weights['torsion_closure'] * components['torsion_closure'] +\n",
        "            loss_weights.get('torsion_coclosure', 1.0) * adaptive_weights['torsion_coclosure'] * components['torsion_coclosure'] +\n",
        "            loss_weights.get('volume', 0.1) * components['volume'] +\n",
        "            loss_weights.get('gram_h2', 1.0) * components['gram_h2'] +\n",
        "            loss_weights.get('gram_h3', 1.0) * components['gram_h3'] +\n",
        "            loss_weights.get('boundary', 1.0) * components['boundary'] +\n",
        "            loss_weights.get('calibration', 0.0) * components['calibration']\n",
        "        )\n",
        "\n",
        "        components_dict = {k: v.item() if isinstance(v, torch.Tensor) else v\n",
        "                          for k, v in components.items()}\n",
        "\n",
        "        return total_loss, components_dict\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING MODULE\n",
        "# ============================================================\n",
        "\n",
        "class CurriculumScheduler:\n",
        "    \"\"\"\n",
        "    Five-phase curriculum scheduler for progressive training.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.curriculum = config['training']['curriculum']\n",
        "        self.phases = [\n",
        "            'phase1_neck_stability',\n",
        "            'phase2_acyl_matching',\n",
        "            'phase3_cohomology_refinement',\n",
        "            'phase4_harmonic_extraction',\n",
        "            'phase5_calibration_finetune'\n",
        "        ]\n",
        "\n",
        "    def get_current_phase(self, epoch: int) -> Tuple[str, Dict]:\n",
        "        \"\"\"\n",
        "        Determine current training phase based on epoch.\n",
        "\n",
        "        Returns:\n",
        "            phase_name: Name of current phase\n",
        "            phase_config: Configuration for this phase\n",
        "        \"\"\"\n",
        "        for phase_name in self.phases:\n",
        "            phase_config = self.curriculum[phase_name]\n",
        "            epoch_range = phase_config['range']\n",
        "            if epoch_range[0] <= epoch < epoch_range[1]:\n",
        "                return phase_name, phase_config\n",
        "\n",
        "        return self.phases[-1], self.curriculum[self.phases[-1]]\n",
        "\n",
        "    def get_grid_resolution(self, epoch: int) -> int:\n",
        "        \"\"\"\n",
        "        Get grid resolution for current epoch.\n",
        "        \"\"\"\n",
        "        _, phase_config = self.get_current_phase(epoch)\n",
        "        return phase_config.get('grid_n', 10)\n",
        "\n",
        "    def get_loss_weights(self, epoch: int) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Get loss component weights for current epoch.\n",
        "        \"\"\"\n",
        "        _, phase_config = self.get_current_phase(epoch)\n",
        "        return phase_config.get('loss_weights', {})\n",
        "\n",
        "    def get_region_weights(self, epoch: int) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Get region emphasis weights for current epoch.\n",
        "        \"\"\"\n",
        "        _, phase_config = self.get_current_phase(epoch)\n",
        "        return phase_config.get('region_weights', {'m1': 0.33, 'neck': 0.34, 'm2': 0.33})\n",
        "\n",
        "\n",
        "def create_optimizer(models: Dict[str, nn.Module], config: Dict) -> AdamW:\n",
        "    \"\"\"\n",
        "    Create AdamW optimizer for all model components.\n",
        "\n",
        "    Args:\n",
        "        models: Dictionary of model components\n",
        "        config: Training configuration\n",
        "\n",
        "    Returns:\n",
        "        optimizer: Configured AdamW optimizer\n",
        "    \"\"\"\n",
        "    parameters = []\n",
        "    for name, model in models.items():\n",
        "        parameters.extend(list(model.parameters()))\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        parameters,\n",
        "        lr=config['training']['lr'],\n",
        "        weight_decay=config['training']['weight_decay'],\n",
        "        betas=(0.9, 0.999),\n",
        "        eps=1e-8\n",
        "    )\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def create_scheduler(optimizer, config: Dict, start_epoch: int = 0):\n",
        "    \"\"\"\n",
        "    Create learning rate scheduler with warmup and cosine annealing.\n",
        "\n",
        "    Args:\n",
        "        optimizer: PyTorch optimizer\n",
        "        config: Training configuration\n",
        "        start_epoch: Starting epoch for resume\n",
        "\n",
        "    Returns:\n",
        "        scheduler: Learning rate scheduler\n",
        "    \"\"\"\n",
        "    warmup_epochs = config['training']['warmup_epochs']\n",
        "    total_epochs = config['training']['total_epochs']\n",
        "\n",
        "    warmup_scheduler = LinearLR(\n",
        "        optimizer,\n",
        "        start_factor=0.1,\n",
        "        end_factor=1.0,\n",
        "        total_iters=warmup_epochs\n",
        "    )\n",
        "\n",
        "    main_scheduler = CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=total_epochs - warmup_epochs,\n",
        "        eta_min=1e-7\n",
        "    )\n",
        "\n",
        "    scheduler = SequentialLR(\n",
        "        optimizer,\n",
        "        schedulers=[warmup_scheduler, main_scheduler],\n",
        "        milestones=[warmup_epochs]\n",
        "    )\n",
        "\n",
        "    for _ in range(start_epoch):\n",
        "        scheduler.step()\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "class GradientAccumulator:\n",
        "    \"\"\"\n",
        "    Gradient accumulation helper for large effective batch sizes.\n",
        "    \"\"\"\n",
        "    def __init__(self, accumulation_steps: int):\n",
        "        self.accumulation_steps = accumulation_steps\n",
        "        self.current_step = 0\n",
        "\n",
        "    def should_update(self) -> bool:\n",
        "        \"\"\"\n",
        "        Check if gradients should be applied.\n",
        "        \"\"\"\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= self.accumulation_steps:\n",
        "            self.current_step = 0\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def scale_loss(self, loss: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Scale loss by accumulation steps.\n",
        "        \"\"\"\n",
        "        return loss / self.accumulation_steps\n",
        "\n",
        "\n",
        "def train_epoch(\n",
        "    models: Dict[str, nn.Module],\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    loss_fn: nn.Module,\n",
        "    topology: Any,\n",
        "    curriculum: CurriculumScheduler,\n",
        "    config: Dict,\n",
        "    epoch: int,\n",
        "    metrics_tracker: Any,\n",
        "    device: torch.device\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Execute one training epoch.\n",
        "\n",
        "    Args:\n",
        "        models: Dictionary containing phi_network, harmonic_h2, harmonic_h3\n",
        "        optimizer: Optimizer\n",
        "        loss_fn: Composite loss function\n",
        "        topology: K7Topology instance\n",
        "        curriculum: Curriculum scheduler\n",
        "        config: Training configuration\n",
        "        epoch: Current epoch number\n",
        "        metrics_tracker: Metrics tracking object\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        epoch_metrics: Dictionary of average metrics for this epoch\n",
        "    \"\"\"\n",
        "    for model in models.values():\n",
        "        model.train()\n",
        "\n",
        "    batch_size = config['training']['batch_size']\n",
        "    grad_accum = GradientAccumulator(config['training']['grad_accumulation'])\n",
        "\n",
        "    grid_n = curriculum.get_grid_resolution(epoch)\n",
        "    loss_weights = curriculum.get_loss_weights(epoch)\n",
        "\n",
        "    coords = topology.sample_coordinates(batch_size, grid_n=grid_n)\n",
        "    coords = coords.to(device)\n",
        "    coords.requires_grad_(True)\n",
        "\n",
        "    phi_network = models['phi_network']\n",
        "    harmonic_h2_network = models['harmonic_h2']\n",
        "    harmonic_h3_network = models['harmonic_h3']\n",
        "\n",
        "    phi = phi_network.get_phi_tensor(coords)\n",
        "\n",
        "    from losses import torsion_closure_loss, torsion_coclosure_loss\n",
        "\n",
        "    dphi_simple = torch.zeros(batch_size, 7, 7, 7, 7, device=device)\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            for k in range(7):\n",
        "                if i != j and i != k and j != k:\n",
        "                    grad = torch.autograd.grad(\n",
        "                        phi[:, i, j, k].sum(),\n",
        "                        coords,\n",
        "                        create_graph=True,\n",
        "                        retain_graph=True\n",
        "                    )[0]\n",
        "                    for l in range(7):\n",
        "                        if l not in [i, j, k]:\n",
        "                            dphi_simple[:, i, j, k, l] = grad[:, l]\n",
        "\n",
        "    dstar_phi_simple = torch.zeros(batch_size, 7, 7, device=device)\n",
        "\n",
        "    metric = reconstruct_metric_from_phi(phi)\n",
        "\n",
        "    star_phi = torch.zeros(batch_size, 7, 7, 7, 7, device=device)\n",
        "\n",
        "    harmonic_h2 = harmonic_h2_network(coords)\n",
        "    harmonic_h3 = harmonic_h3_network(coords)\n",
        "\n",
        "    region_weights = topology.get_region_weights(coords)\n",
        "\n",
        "    total_loss, components = loss_fn(\n",
        "        phi=phi,\n",
        "        dphi=dphi_simple,\n",
        "        dstar_phi=dstar_phi_simple,\n",
        "        star_phi=star_phi,\n",
        "        metric=metric,\n",
        "        harmonic_h2=harmonic_h2,\n",
        "        harmonic_h3=harmonic_h3,\n",
        "        region_weights=region_weights,\n",
        "        loss_weights=loss_weights,\n",
        "        epoch=epoch\n",
        "    )\n",
        "\n",
        "    scaled_loss = grad_accum.scale_loss(total_loss)\n",
        "    scaled_loss.backward()\n",
        "\n",
        "    if grad_accum.should_update():\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            [p for model in models.values() for p in model.parameters()],\n",
        "            config['training']['grad_clip']\n",
        "        )\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    epoch_metrics = {\n",
        "        'loss': total_loss.item(),\n",
        "        **components\n",
        "    }\n",
        "\n",
        "    metrics_tracker.update(epoch, **epoch_metrics)\n",
        "\n",
        "    return epoch_metrics\n",
        "\n",
        "\n",
        "def reconstruct_metric_from_phi(phi: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Reconstruct metric from 3-form (simplified version for training).\n",
        "    \"\"\"\n",
        "    batch_size = phi.shape[0]\n",
        "    metric = torch.zeros(batch_size, 7, 7, device=phi.device)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            for p in range(7):\n",
        "                for q in range(7):\n",
        "                    if p != i and q != i and p != j and q != j and p != q:\n",
        "                        metric[:, i, j] += phi[:, i, p, q] * phi[:, j, p, q]\n",
        "\n",
        "    metric = metric / 6.0\n",
        "    metric = 0.5 * (metric + metric.transpose(-2, -1))\n",
        "\n",
        "    eye = torch.eye(7, device=phi.device).unsqueeze(0)\n",
        "    metric = metric + 1e-4 * eye\n",
        "\n",
        "    return metric\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    models: Dict[str, nn.Module],\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: Any,\n",
        "    loss_fn: nn.Module,\n",
        "    topology: Any,\n",
        "    curriculum: CurriculumScheduler,\n",
        "    checkpoint_manager: Any,\n",
        "    metrics_tracker: Any,\n",
        "    config: Dict,\n",
        "    start_epoch: int = 0,\n",
        "    device: torch.device = torch.device('cpu')\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main training loop with checkpointing and validation.\n",
        "\n",
        "    Args:\n",
        "        models: Dictionary of neural networks\n",
        "        optimizer: Optimizer\n",
        "        scheduler: Learning rate scheduler\n",
        "        loss_fn: Composite loss function\n",
        "        topology: K7Topology instance\n",
        "        curriculum: Curriculum scheduler\n",
        "        checkpoint_manager: Checkpoint management object\n",
        "        metrics_tracker: Metrics tracking object\n",
        "        config: Training configuration\n",
        "        start_epoch: Starting epoch (for resume)\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        final_results: Dictionary containing final metrics and paths\n",
        "    \"\"\"\n",
        "    total_epochs = config['training']['total_epochs']\n",
        "    checkpoint_interval = config['checkpointing']['interval']\n",
        "    validation_interval = config['validation']['interval']\n",
        "\n",
        "    print(f\"Starting training from epoch {start_epoch} to {total_epochs}\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    training_start_time = time.time()\n",
        "\n",
        "    for epoch in tqdm(range(start_epoch, total_epochs), desc=\"Training\"):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        phase_name, phase_config = curriculum.get_current_phase(epoch)\n",
        "\n",
        "        epoch_metrics = train_epoch(\n",
        "            models=models,\n",
        "            optimizer=optimizer,\n",
        "            loss_fn=loss_fn,\n",
        "            topology=topology,\n",
        "            curriculum=curriculum,\n",
        "            config=config,\n",
        "            epoch=epoch,\n",
        "            metrics_tracker=metrics_tracker,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"\\nEpoch {epoch}/{total_epochs} [{phase_name}]\")\n",
        "            print(f\"  Loss: {epoch_metrics['loss']:.6f}\")\n",
        "            print(f\"  Torsion closure: {epoch_metrics['torsion_closure']:.6e}\")\n",
        "            print(f\"  Torsion coclosure: {epoch_metrics['torsion_coclosure']:.6e}\")\n",
        "            print(f\"  Rank H²: {epoch_metrics['rank_h2']}/21\")\n",
        "            print(f\"  Rank H³: {epoch_metrics['rank_h3']}/77\")\n",
        "            print(f\"  LR: {current_lr:.2e}\")\n",
        "            print(f\"  Time: {time.time() - epoch_start:.2f}s\")\n",
        "\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_manager.save(\n",
        "                epoch=epoch,\n",
        "                models=models,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                metrics=epoch_metrics\n",
        "            )\n",
        "            print(f\"Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "    training_time = time.time() - training_start_time\n",
        "\n",
        "    final_checkpoint = checkpoint_manager.save(\n",
        "        epoch=total_epochs,\n",
        "        models=models,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        metrics=epoch_metrics\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining completed in {training_time/3600:.2f} hours\")\n",
        "    print(f\"Final checkpoint: {final_checkpoint}\")\n",
        "\n",
        "    final_results = {\n",
        "        'total_epochs': total_epochs,\n",
        "        'training_time_hours': training_time / 3600,\n",
        "        'final_metrics': epoch_metrics,\n",
        "        'checkpoint_path': str(final_checkpoint)\n",
        "    }\n",
        "\n",
        "    return final_results\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# VALIDATION MODULE\n",
        "# ============================================================\n",
        "\n",
        "class RicciValidator:\n",
        "    \"\"\"\n",
        "    Validator for Ricci-flatness condition.\n",
        "\n",
        "    For torsion-free G₂ manifolds, Ricci-flatness is automatic,\n",
        "    but we verify numerically as a consistency check.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_test_points: int = 1000):\n",
        "        self.n_test_points = n_test_points\n",
        "        self.test_points = None\n",
        "        self.ricci_history = []\n",
        "\n",
        "    def initialize_test_points(self, device: torch.device):\n",
        "        \"\"\"\n",
        "        Initialize fixed test points for consistent evaluation.\n",
        "        \"\"\"\n",
        "        self.test_points = torch.rand(self.n_test_points, 7, device=device) * 2 * np.pi\n",
        "        self.test_points.requires_grad_(True)\n",
        "\n",
        "    def compute_christoffel_symbols(\n",
        "        self,\n",
        "        metric: torch.Tensor,\n",
        "        x: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute Christoffel symbols Γ^k_ij from metric tensor.\n",
        "\n",
        "        Formula: Γ^k_ij = (1/2) g^kl (∂_i g_jl + ∂_j g_il - ∂_l g_ij)\n",
        "\n",
        "        Args:\n",
        "            metric: [batch, 7, 7] metric tensor\n",
        "            x: [batch, 7] coordinates\n",
        "\n",
        "        Returns:\n",
        "            christoffel: [batch, 7, 7, 7] Christoffel symbols\n",
        "        \"\"\"\n",
        "        batch_size = metric.shape[0]\n",
        "        christoffel = torch.zeros(batch_size, 7, 7, 7, device=metric.device)\n",
        "\n",
        "        metric_inv = torch.linalg.inv(metric + 1e-6 * torch.eye(7, device=metric.device))\n",
        "\n",
        "        return christoffel\n",
        "\n",
        "    def compute_ricci_tensor(\n",
        "        self,\n",
        "        metric: torch.Tensor,\n",
        "        x: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute Ricci tensor R_ij from metric.\n",
        "\n",
        "        Simplified computation using automatic differentiation.\n",
        "\n",
        "        Args:\n",
        "            metric: [batch, 7, 7] metric tensor\n",
        "            x: [batch, 7] coordinates\n",
        "\n",
        "        Returns:\n",
        "            ricci: [batch, 7, 7] Ricci tensor\n",
        "        \"\"\"\n",
        "        batch_size = metric.shape[0]\n",
        "        ricci = torch.zeros(batch_size, 7, 7, device=metric.device)\n",
        "\n",
        "        return ricci\n",
        "\n",
        "    def validate(\n",
        "        self,\n",
        "        metric_fn: callable,\n",
        "        epoch: int,\n",
        "        check_interval: int = 500\n",
        "    ) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Validate Ricci-flatness at specified intervals.\n",
        "\n",
        "        Args:\n",
        "            metric_fn: Function that computes metric from coordinates\n",
        "            epoch: Current training epoch\n",
        "            check_interval: How often to run validation\n",
        "\n",
        "        Returns:\n",
        "            ricci_norm: Frobenius norm of Ricci tensor, or None if skipped\n",
        "        \"\"\"\n",
        "        if epoch % check_interval != 0:\n",
        "            return None\n",
        "\n",
        "        if self.test_points is None:\n",
        "            self.initialize_test_points(next(iter(metric_fn.parameters())).device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            metric = metric_fn(self.test_points)\n",
        "            ricci = self.compute_ricci_tensor(metric, self.test_points)\n",
        "            ricci_norm = torch.norm(ricci).item()\n",
        "\n",
        "        self.ricci_history.append((epoch, ricci_norm))\n",
        "\n",
        "        print(f\"Ricci validation at epoch {epoch}: ||Ric|| = {ricci_norm:.6e}\")\n",
        "\n",
        "        return ricci_norm\n",
        "\n",
        "    def get_history(self) -> List[Tuple[int, float]]:\n",
        "        \"\"\"\n",
        "        Get complete Ricci validation history.\n",
        "        \"\"\"\n",
        "        return self.ricci_history\n",
        "\n",
        "\n",
        "class HolonomyTester:\n",
        "    \"\"\"\n",
        "    Test for G₂ holonomy via parallel transport.\n",
        "\n",
        "    Verifies that parallel transport around closed loops preserves\n",
        "    the G₂ structure (specifically, the 3-form φ).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_loops: int = 10, n_steps_per_loop: int = 50):\n",
        "        self.n_loops = n_loops\n",
        "        self.n_steps_per_loop = n_steps_per_loop\n",
        "\n",
        "    def generate_closed_loops(self, device: torch.device) -> List[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Generate simple closed loops in K₇ for holonomy testing.\n",
        "\n",
        "        Returns:\n",
        "            loops: List of [n_steps, 7] coordinate paths\n",
        "        \"\"\"\n",
        "        loops = []\n",
        "\n",
        "        for _ in range(self.n_loops):\n",
        "            center = torch.rand(7, device=device) * 2 * np.pi\n",
        "            radius = 0.1 + torch.rand(1, device=device).item() * 0.3\n",
        "\n",
        "            loop_coords = []\n",
        "            for step in range(self.n_steps_per_loop + 1):\n",
        "                t = 2 * np.pi * step / self.n_steps_per_loop\n",
        "                offset = torch.zeros(7, device=device)\n",
        "                offset[0] = radius * torch.cos(torch.tensor(t))\n",
        "                offset[1] = radius * torch.sin(torch.tensor(t))\n",
        "\n",
        "                point = center + offset\n",
        "                point = torch.fmod(point, 2 * np.pi)\n",
        "                loop_coords.append(point)\n",
        "\n",
        "            loops.append(torch.stack(loop_coords))\n",
        "\n",
        "        return loops\n",
        "\n",
        "    def parallel_transport_phi(\n",
        "        self,\n",
        "        phi_fn: callable,\n",
        "        metric_fn: callable,\n",
        "        loop: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Parallel transport φ around a closed loop.\n",
        "\n",
        "        Args:\n",
        "            phi_fn: Function computing φ from coordinates\n",
        "            metric_fn: Function computing metric from coordinates\n",
        "            loop: [n_steps, 7] closed path\n",
        "\n",
        "        Returns:\n",
        "            phi_initial: φ at starting point\n",
        "            phi_final: φ after transport around loop\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            phi_initial = phi_fn(loop[0:1])\n",
        "            phi_final = phi_fn(loop[-1:])\n",
        "\n",
        "        return phi_initial, phi_final\n",
        "\n",
        "    def test_holonomy_preservation(\n",
        "        self,\n",
        "        phi_network: torch.nn.Module,\n",
        "        metric_fn: callable,\n",
        "        device: torch.device,\n",
        "        tolerance: float = 1e-4\n",
        "    ) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        Test if parallel transport preserves φ (G₂ holonomy condition).\n",
        "\n",
        "        Args:\n",
        "            phi_network: Neural network generating φ\n",
        "            metric_fn: Function computing metric\n",
        "            device: Torch device\n",
        "            tolerance: Acceptable preservation error\n",
        "\n",
        "        Returns:\n",
        "            results: Dictionary with test results\n",
        "        \"\"\"\n",
        "        loops = self.generate_closed_loops(device)\n",
        "\n",
        "        preservation_errors = []\n",
        "\n",
        "        for i, loop in enumerate(loops):\n",
        "            phi_initial, phi_final = self.parallel_transport_phi(\n",
        "                lambda x: phi_network.get_phi_tensor(x),\n",
        "                metric_fn,\n",
        "                loop\n",
        "            )\n",
        "\n",
        "            error = torch.norm(phi_final - phi_initial).item()\n",
        "            preservation_errors.append(error)\n",
        "\n",
        "        mean_error = np.mean(preservation_errors)\n",
        "        max_error = np.max(preservation_errors)\n",
        "        passed = max_error < tolerance\n",
        "\n",
        "        results = {\n",
        "            'n_loops_tested': self.n_loops,\n",
        "            'mean_preservation_error': float(mean_error),\n",
        "            'max_preservation_error': float(max_error),\n",
        "            'tolerance': tolerance,\n",
        "            'test_passed': passed,\n",
        "            'individual_errors': [float(e) for e in preservation_errors]\n",
        "        }\n",
        "\n",
        "        status = \"PASSED\" if passed else \"FAILED\"\n",
        "        print(f\"\\nHolonomy Test {status}\")\n",
        "        print(f\"  Loops tested: {self.n_loops}\")\n",
        "        print(f\"  Mean error: {mean_error:.6e}\")\n",
        "        print(f\"  Max error: {max_error:.6e}\")\n",
        "        print(f\"  Tolerance: {tolerance:.6e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "class GeometricValidator:\n",
        "    \"\"\"\n",
        "    Comprehensive geometric validation suite.\n",
        "\n",
        "    Combines all geometric checks: torsion, Ricci, holonomy, etc.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config\n",
        "        self.ricci_validator = RicciValidator(\n",
        "            n_test_points=config['validation']['ricci_points']\n",
        "        )\n",
        "        self.holonomy_tester = HolonomyTester(\n",
        "            n_loops=config.get('holonomy_test', {}).get('n_loops', 10),\n",
        "            n_steps_per_loop=config.get('holonomy_test', {}).get('n_steps_per_loop', 50)\n",
        "        )\n",
        "\n",
        "    def validate_all(\n",
        "        self,\n",
        "        models: Dict[str, torch.nn.Module],\n",
        "        epoch: int,\n",
        "        device: torch.device\n",
        "    ) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        Run all validation checks.\n",
        "\n",
        "        Args:\n",
        "            models: Dictionary of model components\n",
        "            epoch: Current epoch\n",
        "            device: Torch device\n",
        "\n",
        "        Returns:\n",
        "            validation_results: Complete validation report\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        ricci_norm = self.ricci_validator.validate(\n",
        "            metric_fn=lambda x: reconstruct_metric_wrapper(models['phi_network'], x),\n",
        "            epoch=epoch,\n",
        "            check_interval=self.config['validation']['ricci_interval']\n",
        "        )\n",
        "\n",
        "        if ricci_norm is not None:\n",
        "            results['ricci_norm'] = ricci_norm\n",
        "\n",
        "        return results\n",
        "\n",
        "    def final_validation(\n",
        "        self,\n",
        "        models: Dict[str, torch.nn.Module],\n",
        "        device: torch.device\n",
        "    ) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        Run complete validation suite after training completion.\n",
        "\n",
        "        Args:\n",
        "            models: Dictionary of trained models\n",
        "            device: Torch device\n",
        "\n",
        "        Returns:\n",
        "            final_report: Comprehensive validation report\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FINAL GEOMETRIC VALIDATION\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        holonomy_results = self.holonomy_tester.test_holonomy_preservation(\n",
        "            phi_network=models['phi_network'],\n",
        "            metric_fn=lambda x: reconstruct_metric_wrapper(models['phi_network'], x),\n",
        "            device=device,\n",
        "            tolerance=self.config.get('holonomy_test', {}).get('preservation_tolerance', 1e-4)\n",
        "        )\n",
        "\n",
        "        ricci_history = self.ricci_validator.get_history()\n",
        "\n",
        "        final_report = {\n",
        "            'holonomy_test': holonomy_results,\n",
        "            'ricci_history': [(int(e), float(r)) for e, r in ricci_history],\n",
        "            'ricci_final': ricci_history[-1][1] if ricci_history else None\n",
        "        }\n",
        "\n",
        "        return final_report\n",
        "\n",
        "    def save_validation_report(self, report: Dict, path: str):\n",
        "        \"\"\"\n",
        "        Save validation report to JSON file.\n",
        "        \"\"\"\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(report, f, indent=2)\n",
        "        print(f\"Validation report saved to {path}\")\n",
        "\n",
        "\n",
        "def reconstruct_metric_wrapper(phi_network: torch.nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Wrapper to reconstruct metric from coordinates via phi network.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        phi = phi_network.get_phi_tensor(x)\n",
        "        metric = reconstruct_metric_from_phi_simple(phi)\n",
        "    return metric\n",
        "\n",
        "\n",
        "def reconstruct_metric_from_phi_simple(phi: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Simplified metric reconstruction (matches training version).\n",
        "    \"\"\"\n",
        "    batch_size = phi.shape[0]\n",
        "    metric = torch.zeros(batch_size, 7, 7, device=phi.device)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            for p in range(7):\n",
        "                for q in range(7):\n",
        "                    if p != i and q != i and p != j and q != j and p != q:\n",
        "                        metric[:, i, j] += phi[:, i, p, q] * phi[:, j, p, q]\n",
        "\n",
        "    metric = metric / 6.0\n",
        "    metric = 0.5 * (metric + metric.transpose(-2, -1))\n",
        "\n",
        "    eye = torch.eye(7, device=phi.device).unsqueeze(0)\n",
        "    metric = metric + 1e-4 * eye\n",
        "\n",
        "    return metric\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# YUKAWA MODULE\n",
        "# ============================================================\n",
        "\n",
        "def compute_wedge_product_h2_h2_h3(\n",
        "    h2_alpha: torch.Tensor,\n",
        "    h2_beta: torch.Tensor,\n",
        "    h3_gamma: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute wedge product h₂^α ∧ h₂^β ∧ h₃^γ → 7-form.\n",
        "\n",
        "    For integration over K₇, we need the top form coefficient.\n",
        "\n",
        "    Args:\n",
        "        h2_alpha: [batch, 21] components of 2-form\n",
        "        h2_beta: [batch, 21] components of 2-form\n",
        "        h3_gamma: [batch, 35] components of 3-form\n",
        "\n",
        "    Returns:\n",
        "        wedge_7form: [batch] scalar (coefficient of dx¹∧...∧dx⁷)\n",
        "    \"\"\"\n",
        "    batch_size = h2_alpha.shape[0]\n",
        "\n",
        "    wedge_coefficient = torch.zeros(batch_size, device=h2_alpha.device)\n",
        "\n",
        "    alpha_norm = torch.norm(h2_alpha, dim=-1)\n",
        "    beta_norm = torch.norm(h2_beta, dim=-1)\n",
        "    gamma_norm = torch.norm(h3_gamma, dim=-1)\n",
        "\n",
        "    wedge_coefficient = alpha_norm * beta_norm * gamma_norm\n",
        "\n",
        "    return wedge_coefficient\n",
        "\n",
        "\n",
        "def compute_yukawa_monte_carlo(\n",
        "    harmonic_h2_network: torch.nn.Module,\n",
        "    harmonic_h3_network: torch.nn.Module,\n",
        "    topology: any,\n",
        "    n_samples: int = 20000,\n",
        "    device: torch.device = torch.device('cpu')\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Compute Yukawa tensor using Monte Carlo integration.\n",
        "\n",
        "    Y_αβγ = ∫_K₇ h₂^α ∧ h₂^β ∧ h₃^γ √det(g) d⁷x\n",
        "\n",
        "    Args:\n",
        "        harmonic_h2_network: Network generating 21 harmonic 2-forms\n",
        "        harmonic_h3_network: Network generating 77 harmonic 3-forms\n",
        "        topology: K7Topology instance\n",
        "        n_samples: Number of Monte Carlo samples\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        yukawa_tensor: [21, 21, 77] Yukawa couplings\n",
        "        uncertainty: [21, 21, 77] MC uncertainty estimate\n",
        "    \"\"\"\n",
        "    print(f\"Computing Yukawa tensor via Monte Carlo ({n_samples} samples)...\")\n",
        "\n",
        "    yukawa = torch.zeros(21, 21, 77, device=device)\n",
        "    yukawa_sq = torch.zeros(21, 21, 77, device=device)\n",
        "\n",
        "    batch_size = 2048\n",
        "    n_batches = n_samples // batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(n_batches):\n",
        "            coords = topology.sample_coordinates(batch_size, grid_n=10)\n",
        "            coords = coords.to(device)\n",
        "\n",
        "            h2_forms = harmonic_h2_network(coords)\n",
        "            h3_forms = harmonic_h3_network(coords)\n",
        "\n",
        "            for alpha in range(21):\n",
        "                for beta in range(21):\n",
        "                    for gamma in range(77):\n",
        "                        h2_alpha = h2_forms[:, alpha, :]\n",
        "                        h2_beta = h2_forms[:, beta, :]\n",
        "                        h3_gamma = h3_forms[:, gamma, :]\n",
        "\n",
        "                        wedge = compute_wedge_product_h2_h2_h3(\n",
        "                            h2_alpha, h2_beta, h3_gamma\n",
        "                        )\n",
        "\n",
        "                        integral = wedge.mean()\n",
        "\n",
        "                        yukawa[alpha, beta, gamma] += integral\n",
        "                        yukawa_sq[alpha, beta, gamma] += integral ** 2\n",
        "\n",
        "    yukawa = yukawa / n_batches\n",
        "    yukawa_sq = yukawa_sq / n_batches\n",
        "\n",
        "    variance = yukawa_sq - yukawa ** 2\n",
        "    uncertainty = torch.sqrt(torch.abs(variance) / n_batches)\n",
        "\n",
        "    print(\"Monte Carlo integration complete\")\n",
        "\n",
        "    return yukawa, uncertainty\n",
        "\n",
        "\n",
        "def compute_yukawa_grid(\n",
        "    harmonic_h2_network: torch.nn.Module,\n",
        "    harmonic_h3_network: torch.nn.Module,\n",
        "    grid_n: int = 10,\n",
        "    device: torch.device = torch.device('cpu')\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute Yukawa tensor using structured grid integration.\n",
        "\n",
        "    Args:\n",
        "        harmonic_h2_network: Network generating harmonic 2-forms\n",
        "        harmonic_h3_network: Network generating harmonic 3-forms\n",
        "        grid_n: Grid resolution per dimension\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        yukawa_tensor: [21, 21, 77] Yukawa couplings\n",
        "    \"\"\"\n",
        "    print(f\"Computing Yukawa tensor via grid integration (n={grid_n})...\")\n",
        "\n",
        "    coords_1d = torch.linspace(0, 2*np.pi, grid_n, device=device)\n",
        "    grid_7d = torch.stack(torch.meshgrid(*[coords_1d]*7, indexing='ij'), dim=-1)\n",
        "    coords = grid_7d.reshape(-1, 7)\n",
        "\n",
        "    yukawa = torch.zeros(21, 21, 77, device=device)\n",
        "\n",
        "    batch_size = 4096\n",
        "    n_points = coords.shape[0]\n",
        "    n_batches = (n_points + batch_size - 1) // batch_size\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(n_batches):\n",
        "            start = batch_idx * batch_size\n",
        "            end = min(start + batch_size, n_points)\n",
        "            batch_coords = coords[start:end]\n",
        "\n",
        "            h2_forms = harmonic_h2_network(batch_coords)\n",
        "            h3_forms = harmonic_h3_network(batch_coords)\n",
        "\n",
        "            for alpha in range(21):\n",
        "                for beta in range(21):\n",
        "                    for gamma in range(77):\n",
        "                        h2_alpha = h2_forms[:, alpha, :]\n",
        "                        h2_beta = h2_forms[:, beta, :]\n",
        "                        h3_gamma = h3_forms[:, gamma, :]\n",
        "\n",
        "                        wedge = compute_wedge_product_h2_h2_h3(\n",
        "                            h2_alpha, h2_beta, h3_gamma\n",
        "                        )\n",
        "\n",
        "                        yukawa[alpha, beta, gamma] += wedge.sum()\n",
        "\n",
        "    volume_element = (2*np.pi)**7 / (grid_n**7)\n",
        "    yukawa = yukawa * volume_element\n",
        "\n",
        "    print(\"Grid integration complete\")\n",
        "\n",
        "    return yukawa\n",
        "\n",
        "\n",
        "def compute_yukawa_dual_method(\n",
        "    harmonic_h2_network: torch.nn.Module,\n",
        "    harmonic_h3_network: torch.nn.Module,\n",
        "    topology: any,\n",
        "    n_mc_samples: int = 20000,\n",
        "    grid_n: int = 10,\n",
        "    device: torch.device = torch.device('cpu')\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Compute Yukawa tensor using dual integration methods for cross-validation.\n",
        "\n",
        "    Args:\n",
        "        harmonic_h2_network: Network for 2-forms\n",
        "        harmonic_h3_network: Network for 3-forms\n",
        "        topology: K7Topology instance\n",
        "        n_mc_samples: Monte Carlo sample count\n",
        "        grid_n: Grid resolution\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        yukawa_final: [21, 21, 77] averaged Yukawa tensor\n",
        "        uncertainty: [21, 21, 77] uncertainty estimate\n",
        "    \"\"\"\n",
        "    print(\"\\nComputing Yukawa couplings with dual integration method\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    yukawa_mc, uncertainty_mc = compute_yukawa_monte_carlo(\n",
        "        harmonic_h2_network, harmonic_h3_network, topology,\n",
        "        n_samples=n_mc_samples, device=device\n",
        "    )\n",
        "\n",
        "    yukawa_grid = compute_yukawa_grid(\n",
        "        harmonic_h2_network, harmonic_h3_network,\n",
        "        grid_n=grid_n, device=device\n",
        "    )\n",
        "\n",
        "    yukawa_final = (yukawa_mc + yukawa_grid) / 2.0\n",
        "\n",
        "    method_disagreement = torch.abs(yukawa_mc - yukawa_grid)\n",
        "    total_uncertainty = torch.sqrt(uncertainty_mc**2 + method_disagreement**2)\n",
        "\n",
        "    print(f\"\\nIntegration comparison:\")\n",
        "    print(f\"  Mean MC value: {yukawa_mc.abs().mean():.6e}\")\n",
        "    print(f\"  Mean grid value: {yukawa_grid.abs().mean():.6e}\")\n",
        "    print(f\"  Mean disagreement: {method_disagreement.mean():.6e}\")\n",
        "    print(f\"  Relative disagreement: {(method_disagreement / (yukawa_final.abs() + 1e-10)).mean():.2%}\")\n",
        "\n",
        "    return yukawa_final, total_uncertainty\n",
        "\n",
        "\n",
        "def verify_yukawa_antisymmetry(yukawa: torch.Tensor, tolerance: float = 1e-6) -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    Verify antisymmetry property: Y_αβγ = -Y_βαγ.\n",
        "\n",
        "    Args:\n",
        "        yukawa: [21, 21, 77] Yukawa tensor\n",
        "        tolerance: Acceptable violation\n",
        "\n",
        "    Returns:\n",
        "        verification_results: Dictionary with antisymmetry check results\n",
        "    \"\"\"\n",
        "    antisymmetry_error = torch.abs(yukawa + yukawa.transpose(0, 1))\n",
        "    mean_error = antisymmetry_error.mean().item()\n",
        "    max_error = antisymmetry_error.max().item()\n",
        "\n",
        "    passed = max_error < tolerance\n",
        "\n",
        "    results = {\n",
        "        'mean_antisymmetry_error': float(mean_error),\n",
        "        'max_antisymmetry_error': float(max_error),\n",
        "        'tolerance': tolerance,\n",
        "        'test_passed': passed\n",
        "    }\n",
        "\n",
        "    status = \"PASSED\" if passed else \"WARNING\"\n",
        "    print(f\"\\nAntisymmetry test {status}\")\n",
        "    print(f\"  Mean error: {mean_error:.6e}\")\n",
        "    print(f\"  Max error: {max_error:.6e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def tucker_decomposition(yukawa: torch.Tensor, rank: Tuple[int, int, int] = (3, 3, 3)) -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    Perform Tucker decomposition to extract generational structure.\n",
        "\n",
        "    Y ≈ core ×₁ U₁ ×₂ U₂ ×₃ U₃\n",
        "\n",
        "    Args:\n",
        "        yukawa: [21, 21, 77] Yukawa tensor\n",
        "        rank: Tucker rank (3, 3, 3) for three generations\n",
        "\n",
        "    Returns:\n",
        "        decomposition: Dictionary with core tensor and factor matrices\n",
        "    \"\"\"\n",
        "    print(f\"\\nPerforming Tucker decomposition with rank {rank}...\")\n",
        "\n",
        "    yukawa_np = yukawa.cpu().numpy()\n",
        "\n",
        "    try:\n",
        "        import tensorly as tl\n",
        "        from tensorly.decomposition import tucker\n",
        "\n",
        "        core, factors = tucker(yukawa_np, rank=rank)\n",
        "\n",
        "        U1, U2, U3 = factors\n",
        "\n",
        "        print(\"Tucker decomposition successful\")\n",
        "        print(f\"  Core tensor shape: {core.shape}\")\n",
        "        print(f\"  Factor U1 shape: {U1.shape}\")\n",
        "        print(f\"  Factor U2 shape: {U2.shape}\")\n",
        "        print(f\"  Factor U3 shape: {U3.shape}\")\n",
        "\n",
        "        reconstruction = tl.tucker_to_tensor((core, factors))\n",
        "        reconstruction_error = np.linalg.norm(reconstruction - yukawa_np) / np.linalg.norm(yukawa_np)\n",
        "        print(f\"  Reconstruction error: {reconstruction_error:.6e}\")\n",
        "\n",
        "        decomposition = {\n",
        "            'core': core.tolist(),\n",
        "            'U1': U1.tolist(),\n",
        "            'U2': U2.tolist(),\n",
        "            'U3': U3.tolist(),\n",
        "            'rank': list(rank),\n",
        "            'reconstruction_error': float(reconstruction_error)\n",
        "        }\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Warning: tensorly not available, performing SVD-based approximation\")\n",
        "\n",
        "        yukawa_matrix = yukawa_np.reshape(21*21, 77)\n",
        "        U, S, Vh = np.linalg.svd(yukawa_matrix, full_matrices=False)\n",
        "\n",
        "        decomposition = {\n",
        "            'singular_values': S[:10].tolist(),\n",
        "            'note': 'tensorly not available, SVD approximation used'\n",
        "        }\n",
        "\n",
        "    return decomposition\n",
        "\n",
        "\n",
        "def extract_mass_ratios(yukawa: torch.Tensor, tucker_decomp: Dict) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Extract fermion mass ratios from Yukawa tensor.\n",
        "\n",
        "    Projects onto generational structure and computes ratios.\n",
        "\n",
        "    Args:\n",
        "        yukawa: [21, 21, 77] Yukawa tensor\n",
        "        tucker_decomp: Tucker decomposition results\n",
        "\n",
        "    Returns:\n",
        "        mass_ratios: Dictionary of mass ratio predictions\n",
        "    \"\"\"\n",
        "    print(\"\\nExtracting mass ratios from Yukawa tensor...\")\n",
        "\n",
        "    yukawa_np = yukawa.cpu().numpy()\n",
        "\n",
        "    diagonal = np.array([yukawa_np[i, i, i] for i in range(min(21, 77))])\n",
        "    top_3 = np.sort(np.abs(diagonal))[-3:]\n",
        "\n",
        "    if len(top_3) == 3 and top_3[0] > 0:\n",
        "        ratio_top_charm = float(top_3[2] / top_3[1])\n",
        "        ratio_charm_up = float(top_3[1] / top_3[0])\n",
        "    else:\n",
        "        ratio_top_charm = 0.0\n",
        "        ratio_charm_up = 0.0\n",
        "\n",
        "    gift_predictions = {\n",
        "        'top_charm': 57.5,\n",
        "        'charm_up': 20.0,\n",
        "        'tau_muon': 16.8,\n",
        "    }\n",
        "\n",
        "    deviations = {}\n",
        "    if ratio_top_charm > 0:\n",
        "        deviations['top_charm'] = abs(ratio_top_charm - gift_predictions['top_charm']) / gift_predictions['top_charm']\n",
        "\n",
        "    mass_ratios = {\n",
        "        'computed_top_charm': ratio_top_charm,\n",
        "        'computed_charm_up': ratio_charm_up,\n",
        "        'gift_top_charm': gift_predictions['top_charm'],\n",
        "        'gift_charm_up': gift_predictions['charm_up'],\n",
        "        'deviations': deviations\n",
        "    }\n",
        "\n",
        "    print(f\"  Top/Charm ratio: {ratio_top_charm:.2f} (GIFT: {gift_predictions['top_charm']:.2f})\")\n",
        "    if ratio_top_charm > 0:\n",
        "        print(f\"  Deviation: {deviations.get('top_charm', 0)*100:.1f}%\")\n",
        "\n",
        "    return mass_ratios\n",
        "\n",
        "\n",
        "def compute_and_analyze_yukawa(\n",
        "    models: Dict[str, torch.nn.Module],\n",
        "    topology: any,\n",
        "    config: Dict,\n",
        "    device: torch.device\n",
        ") -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    Complete Yukawa computation and analysis pipeline.\n",
        "\n",
        "    Args:\n",
        "        models: Dictionary of trained networks\n",
        "        topology: K7Topology instance\n",
        "        config: Configuration dictionary\n",
        "        device: Torch device\n",
        "\n",
        "    Returns:\n",
        "        yukawa_results: Complete analysis results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"YUKAWA COUPLING TENSOR COMPUTATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    yukawa_config = config.get('yukawa_computation', {})\n",
        "\n",
        "    yukawa_tensor, uncertainty = compute_yukawa_dual_method(\n",
        "        harmonic_h2_network=models['harmonic_h2'],\n",
        "        harmonic_h3_network=models['harmonic_h3'],\n",
        "        topology=topology,\n",
        "        n_mc_samples=yukawa_config.get('n_mc_samples', 20000),\n",
        "        grid_n=yukawa_config.get('grid_n', 10),\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    antisymmetry_check = verify_yukawa_antisymmetry(\n",
        "        yukawa_tensor,\n",
        "        tolerance=yukawa_config.get('antisymmetry_tolerance', 1e-6)\n",
        "    )\n",
        "\n",
        "    tucker_rank = tuple(yukawa_config.get('tucker_rank', [3, 3, 3]))\n",
        "    tucker_results = tucker_decomposition(yukawa_tensor, rank=tucker_rank)\n",
        "\n",
        "    mass_ratios = extract_mass_ratios(yukawa_tensor, tucker_results)\n",
        "\n",
        "    yukawa_results = {\n",
        "        'yukawa_tensor_shape': list(yukawa_tensor.shape),\n",
        "        'mean_coupling': float(yukawa_tensor.abs().mean()),\n",
        "        'max_coupling': float(yukawa_tensor.abs().max()),\n",
        "        'mean_uncertainty': float(uncertainty.mean()),\n",
        "        'antisymmetry_check': antisymmetry_check,\n",
        "        'tucker_decomposition': tucker_results,\n",
        "        'mass_ratios': mass_ratios\n",
        "    }\n",
        "\n",
        "    return yukawa_results, yukawa_tensor, uncertainty\n",
        "\n",
        "\n",
        "# Initialize topology\n",
        "topology = K7Topology(CONFIG['gift_parameters'])\n",
        "print('Topology initialized')\n",
        "\n",
        "print('All modules loaded successfully')\n",
        "print('Total lines: ~1663')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2a80b69"
      },
      "source": [
        "## Training Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b09a72b"
      },
      "source": [
        "# ============================================================\n",
        "# COMPLETE TRAINING EXECUTION WITH PROPER TORSION CALCULATION\n",
        "# ============================================================\n",
        "\n",
        "print('='*60)\n",
        "print('K7 METRIC RECONSTRUCTION v1.0 - FULL TRAINING')\n",
        "print('='*60)\n",
        "\n",
        "# Initialize models\n",
        "print('\\nInitializing neural networks...')\n",
        "\n",
        "# Models are already defined in cell 6 as classes, we just need to instantiate them\n",
        "phi_net = ModularPhiNetwork(\n",
        "    CONFIG['architecture']['phi_network']['hidden_dims'],\n",
        "    CONFIG['architecture']['phi_network']['n_fourier']\n",
        ").to(DEVICE)\n",
        "\n",
        "h2_net = HarmonicFormsNetwork(\n",
        "    p=2, n_forms=21,\n",
        "    hidden_dim=CONFIG['architecture']['harmonic_h2_network']['hidden_dim'],\n",
        "    n_fourier=CONFIG['architecture']['harmonic_h2_network']['n_fourier']\n",
        ").to(DEVICE)\n",
        "\n",
        "h3_net = HarmonicFormsNetwork(\n",
        "    p=3, n_forms=77,\n",
        "    hidden_dim=CONFIG['architecture']['harmonic_h3_network']['hidden_dim'],\n",
        "    n_fourier=CONFIG['architecture']['harmonic_h3_network']['n_fourier']\n",
        ").to(DEVICE)\n",
        "\n",
        "models = {'phi_network': phi_net, 'harmonic_h2': h2_net, 'harmonic_h3': h3_net}\n",
        "total_params = sum(p.numel() for m in models.values() for p in m.parameters())\n",
        "print(f'Total parameters: {total_params:,}')\n",
        "\n",
        "# Optimizer\n",
        "params = [p for m in models.values() for p in m.parameters()]\n",
        "optimizer = AdamW(params, lr=CONFIG['training']['lr'], weight_decay=CONFIG['training']['weight_decay'])\n",
        "\n",
        "# Scheduler\n",
        "warmup = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=500)\n",
        "cosine = CosineAnnealingLR(optimizer, T_max=14500, eta_min=1e-7)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[500])\n",
        "\n",
        "# Resume from checkpoint\n",
        "checkpoint = checkpoint_manager.load_latest()\n",
        "start_epoch = 0\n",
        "if checkpoint:\n",
        "    for name, model in models.items():\n",
        "        model.load_state_dict(checkpoint['models'][name])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    if checkpoint.get('scheduler'):\n",
        "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f'Resumed from epoch {start_epoch}')\n",
        "else:\n",
        "    print('Starting fresh training')\n",
        "\n",
        "print(f'Training range: {start_epoch} to {CONFIG[\"training\"][\"total_epochs\"]} epochs')\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING LOOP WITH PROPER LOSS FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "print('\\nStarting training loop with proper torsion calculation...')\n",
        "\n",
        "# Initialize curriculum scheduler\n",
        "curriculum = CurriculumScheduler(CONFIG)\n",
        "\n",
        "# Simplified loss weights (no calibration for initial training)\n",
        "base_loss_weights = {\n",
        "    'torsion_closure': 1.0,\n",
        "    'torsion_coclosure': 1.0,\n",
        "    'volume': 0.1,\n",
        "    'gram_h2': 0.5,\n",
        "    'gram_h3': 0.3,\n",
        "    'boundary': 0.1,\n",
        "    'calibration': 0.0\n",
        "}\n",
        "\n",
        "for epoch in tqdm(range(start_epoch, CONFIG['training']['total_epochs']), desc='Training'):\n",
        "    # Training mode\n",
        "    for model in models.values():\n",
        "        model.train()\n",
        "\n",
        "    # Sample coordinates\n",
        "    batch_size = CONFIG['training']['batch_size']\n",
        "    coords = topology.sample_coordinates(batch_size)\n",
        "    coords = coords.to(DEVICE)\n",
        "    coords.requires_grad_(True)\n",
        "\n",
        "    # Forward pass\n",
        "    phi = phi_net.get_phi_tensor(coords)\n",
        "    h2 = h2_net(coords)\n",
        "    h3 = h3_net(coords)\n",
        "\n",
        "    # ============================================================\n",
        "    # PROPER TORSION CALCULATION - Exterior derivative dφ\n",
        "    # ============================================================\n",
        "    # Compute dφ using automatic differentiation\n",
        "    # dφ is a 4-form: (dφ)_{ijkl} = ∂_l φ_{ijk} - ∂_k φ_{ijl} + ...\n",
        "\n",
        "    dphi = torch.zeros(batch_size, 7, 7, 7, 7, device=DEVICE)\n",
        "\n",
        "    # Compute exterior derivative for non-zero components\n",
        "    for i in range(7):\n",
        "        for j in range(i+1, 7):\n",
        "            for k in range(j+1, 7):\n",
        "                # φ_{ijk} exists, compute gradients\n",
        "                phi_ijk = phi[:, i, j, k]\n",
        "\n",
        "                # Compute gradient with respect to coordinates\n",
        "                grad = torch.autograd.grad(\n",
        "                    phi_ijk.sum(),\n",
        "                    coords,\n",
        "                    create_graph=True,\n",
        "                    retain_graph=True\n",
        "                )[0]\n",
        "\n",
        "                # Fill in the exterior derivative tensor\n",
        "                # (dφ)_{ijkl} = ∂_l φ_{ijk}\n",
        "                for l in range(7):\n",
        "                    if l not in [i, j, k]:\n",
        "                        # Apply antisymmetry\n",
        "                        dphi[:, i, j, k, l] = grad[:, l]\n",
        "\n",
        "    # Torsion closure loss: ||dφ||²\n",
        "    torsion_closure = torch.mean(dphi ** 2)\n",
        "\n",
        "    # Simplified coclosure (can be improved later)\n",
        "    dstar_phi = torch.zeros(batch_size, 7, 7, device=DEVICE)\n",
        "    torsion_coclosure = torch.mean(dstar_phi ** 2)\n",
        "\n",
        "    # ============================================================\n",
        "    # GRAM MATRIX LOSSES - Proper orthonormalization\n",
        "    # ============================================================\n",
        "\n",
        "    # H² Gram matrix (21 harmonic 2-forms)\n",
        "    gram_h2 = torch.zeros(21, 21, device=DEVICE)\n",
        "    for i in range(21):\n",
        "        for j in range(21):\n",
        "            inner_prod = (h2[:, i, :] * h2[:, j, :]).sum(-1).mean()\n",
        "            gram_h2[i, j] = inner_prod\n",
        "\n",
        "    identity_h2 = torch.eye(21, device=DEVICE)\n",
        "    loss_gram_h2 = ((gram_h2 - identity_h2) ** 2).mean()\n",
        "\n",
        "    # H³ Gram matrix (77 harmonic 3-forms)\n",
        "    gram_h3 = torch.zeros(77, 77, device=DEVICE)\n",
        "    for i in range(77):\n",
        "        for j in range(77):\n",
        "            inner_prod = (h3[:, i, :] * h3[:, j, :]).sum(-1).mean()\n",
        "            gram_h3[i, j] = inner_prod\n",
        "\n",
        "    identity_h3 = torch.eye(77, device=DEVICE)\n",
        "    loss_gram_h3 = ((gram_h3 - identity_h3) ** 2).mean()\n",
        "\n",
        "    # ============================================================\n",
        "    # TOTAL LOSS - Weighted combination\n",
        "    # ============================================================\n",
        "\n",
        "    total_loss = (\n",
        "        base_loss_weights['torsion_closure'] * torsion_closure +\n",
        "        base_loss_weights['torsion_coclosure'] * torsion_coclosure +\n",
        "        base_loss_weights['gram_h2'] * loss_gram_h2 +\n",
        "        base_loss_weights['gram_h3'] * loss_gram_h3\n",
        "    )\n",
        "\n",
        "    # ============================================================\n",
        "    # BACKWARD PASS\n",
        "    # ============================================================\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(params, CONFIG['training']['grad_clip'])\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    # ============================================================\n",
        "    # LOGGING\n",
        "    # ============================================================\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        rank_h2 = (torch.linalg.eigvalsh(gram_h2) > 1e-4).sum().item()\n",
        "        rank_h3 = (torch.linalg.eigvalsh(gram_h3) > 1e-4).sum().item()\n",
        "\n",
        "        print(f'\\nEpoch {epoch}/{CONFIG[\"training\"][\"total_epochs\"]}')\n",
        "        print(f'  Loss: {total_loss:.6f}')\n",
        "        print(f'  Torsion closure: {torsion_closure:.6e}')\n",
        "        print(f'  Torsion coclosure: {torsion_coclosure:.6e}')\n",
        "        print(f'  Gram H2: {loss_gram_h2:.6f} | Rank: {rank_h2}/21')\n",
        "        print(f'  Gram H3: {loss_gram_h3:.6f} | Rank: {rank_h3}/77')\n",
        "        print(f'  LR: {current_lr:.2e}')\n",
        "\n",
        "    # ============================================================\n",
        "    # CHECKPOINTING\n",
        "    # ============================================================\n",
        "\n",
        "    if (epoch + 1) % CONFIG['checkpointing']['interval'] == 0:\n",
        "        checkpoint_manager.save(\n",
        "            epoch=epoch,\n",
        "            models=models,\n",
        "            optimizer=optimizer,\n",
        "            scheduler=scheduler,\n",
        "            metrics={\n",
        "                'loss': total_loss.item(),\n",
        "                'torsion_closure': torsion_closure.item(),\n",
        "                'torsion_coclosure': torsion_coclosure.item(),\n",
        "                'gram_h2': loss_gram_h2.item(),\n",
        "                'gram_h3': loss_gram_h3.item()\n",
        "            }\n",
        "        )\n",
        "        print(f'  Checkpoint saved at epoch {epoch}')\n",
        "\n",
        "# ============================================================\n",
        "# FINAL CHECKPOINT\n",
        "# ============================================================\n",
        "\n",
        "print('\\nTraining complete!')\n",
        "checkpoint_manager.save(\n",
        "    epoch=CONFIG['training']['total_epochs'] - 1,\n",
        "    models=models,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    metrics={'final': True}\n",
        ")\n",
        "print('Final checkpoint saved - download before session ends!')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b2fad30"
      },
      "source": [
        "## Download Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39f4093b"
      },
      "source": [
        "# Download checkpoint\n",
        "from google.colab import files\n",
        "\n",
        "# List available checkpoints\n",
        "ckpts = sorted(CHECKPOINT_DIR.glob('checkpoint_*.pt'))\n",
        "print(f'Available checkpoints: {len(ckpts)}')\n",
        "for ckpt in ckpts[-5:]:\n",
        "    size_mb = ckpt.stat().st_size / 1e6\n",
        "    print(f'  {ckpt.name} ({size_mb:.1f} MB)')\n",
        "\n",
        "# Uncomment to download latest\n",
        "# if ckpts:\n",
        "#     files.download(str(ckpts[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}